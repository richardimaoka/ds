<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=UTF-8" http-equiv="Content-Type" />
<meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible" />
<meta content="Asciidoctor 1.5.2" name="generator" />
<title>DS201: DataStax Enterprise Foundations of Apache Cassandra</title>
<link href="deck.js/themes/style/font.css" rel="stylesheet" />
<style>
.conum { display: inline-block; color: white !important; background-color: #222222; -webkit-border-radius: 100px; border-radius: 100px; text-align: center; width: 1.2em; height: 1.2em; font-size: 0.9em; font-weight: bold; line-height: 1.2; font-family: Arial, sans-serif; font-style: normal; position: relative; top: -0.1em; }
.conum * { color: white !important; }
.conum + b { display: none; }
.conum:after { content: attr(data-value); }
.conum:not([data-value]):empty { display: none; }
.colist table td:first-of-type { padding-right: 0.25em; }
</style>
<style>
/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
/*pre.CodeRay {background-color:#f7f7f8;}*/
.CodeRay .line-numbers{border-right:1px solid #d8d8d8;padding:0 0.5em 0 .25em}
.CodeRay span.line-numbers{display:inline-block;margin-right:.5em;color:rgba(0,0,0,.3)}
.CodeRay .line-numbers strong{font-weight: normal}
table.CodeRay{border-collapse:separate;border-spacing:0;margin-bottom:0;border:0;background:none}
table.CodeRay td{vertical-align: top}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.line-numbers>pre{padding:0;color:rgba(0,0,0,.3)}
table.CodeRay td.code{padding:0 0 0 .5em}
table.CodeRay td.code>pre{padding:0}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#00}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
<link href="deck.js/core/deck.core.css" rel="stylesheet" />
<link href="deck.js/extensions/scale/deck.scale.css" media="screen" rel="stylesheet" />
<link href="deck.js/extensions/goto/deck.goto.css" media="screen" rel="stylesheet" />
<link href="deck.js/themes/style/datastax.css" media="screen" rel="stylesheet" />
<link href="deck.js/themes/transition/fade.css" media="screen" rel="stylesheet" />
<link href="deck.js/core/print.css" media="print" rel="stylesheet" />
<script src="deck.js/modernizr.custom.js"></script>
</head>
<body class="article">
<div class="deck-container">
<section class="slide" id="title-slide">
<h1>DS201: DataStax Enterprise Foundations of Apache Cassandra</h1>
</section>
<section class="slide transition-green" id="courses-DS201-custom-content-course-introduction">
<h2>Course Introduction</h2>

</section>
<section class="slide" id="student-introduction">
<h2>Student Introduction</h2>
<div class="ulist">
<ul>
<li>Name</li>
<li>Where you are from</li>
<li>Where you work</li>
<li>Goals for using Cassandra</li>
<li>Prior experience</li>
<li>Personal trivia</li>
</ul>
</div>
</section>
<section class="slide" id="learning-objectives">
<h2>Learning Objectives</h2>
<div class="ulist">
<ul>
<li class="slide">Explore KillrVideo domain</li>
<li class="slide">Install/start Cassandra</li>
<li class="slide">Create tables, store, and retrieve data</li>
<li class="slide">Understand the Cassandra data model</li>
<li class="slide">Understand Cassandra architecture</li>
</ul>
</div>
</section>
<section class="slide" id="courses-DS220-data-modeling-overview-killrvideo-story">
<h2>KillrVideo, Inc.</h2>
<div class="paragraph"><p><strong>KillrVideo is a video sharing website</strong></p></div>
<div class="paragraph"><p><span class="image"><img alt="killrvideo-features" src="images/courses/DS220/data-modeling/overview/killrvideo-story/killrvideo-features.svg" /></span></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Features:</p></div>
<div class="ulist">
<ul>
<li>User accounts/user ratings/user comments</li>
<li><p>
Movies and TV shows<div class="ulist">
<ul>
<li>Trailers available for preview</li>
<li>Movies and TV shows licensed from publishers</li>
<li>Parental restrictions based on video&#8217;s MPAA rating or parental guidelines</li>
</ul>
</div></p></li>
<li>Encoding to accommodate playback on mobile devices as well as large TVs</li>
<li>Search videos per user or by title, year, actor, director, genre</li>
<li>Playback tracking allowing pausing and continuing videos at a later date</li>
</ul>
</div>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>The KillrVideo domain has several features we see listed here. Most notably KillrVideo not only stores licensed content but also user-generated content as well. There are other typical video-sharing features such as parental controls, searching, and also tracking where users left off while watching a video.</p></div>
</div>
</div>
</section>
<section class="slide" id="problems-killrvideo-faces">
<h2>Problems KillrVideo Faces</h2>
<div class="paragraph"><p><span class="image" style="float: right"><img alt="frustrated-user" src="images/courses/DS220/data-modeling/overview/killrvideo-story/frustrated-user.jpg" /></span></p></div>
<div class="ulist">
<ul>
<li>Scalability&#8212;&#8203;KillrVideo constantly adds users and videos</li>
<li>Reliability&#8212;&#8203;KillrVideo must always be available</li>
<li>Ease of use&#8212;&#8203;KillrVideo must be easy to manage and maintain</li>
</ul>
</div>
<div class="paragraph notes"><p>KillrVideo found too much success too early and is frantically trying to keep up with its growth. Users constantly push new content, consume content, etc. The KillrVideo team needs a simple mechanism to store/retrieve this content which continues coming at a fast pace.</p></div>
</section>
<section class="slide" id="solutions-attempted">
<h2>Solutions Attempted</h2>
<div class="paragraph"><p><strong>Relational Database Problems</strong></p></div>
<div class="imageblock float-right">
<div class="content">
<img alt="relational problems" src="images/courses/DS220/data-modeling/overview/killrvideo-story/relational-problems.svg" />
</div>
</div>
<div class="ulist">
<ul>
<li>Single points of failure</li>
<li>Scaling complexity</li>
<li>Reliability issues</li>
<li>Difficult to serve users worldwide</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Currently KillrVideo stores its data in a relational database. However, this leader/follower architecture causes a single point of failure when the database crashes.</p></div>
<div class="paragraph"><p>KillrVideo also found that scaling their relational database is doable but difficult. Users on the other side of the world experience lag on the site simply because of their geographical location. Ideally the KillrVideo team could store their data in both the eastern and western hemispheres so all users can enjoy a pleasant viewing experience.</p></div>
</div>
</div>
</section>
<section class="slide" id="killrvideo-and-cassandra">
<h2>KillrVideo and Cassandra</h2>
<div class="paragraph"><p><strong>Why Cassandra</strong></p></div>
<div class="paragraph"><p><span class="image" style="float: right"><img alt="nodes" src="images/courses/DS220/data-modeling/overview/killrvideo-story/nodes.svg" /></span></p></div>
<div class="ulist">
<ul>
<li>Peers instead of leader/follower</li>
<li>Linear scale performance</li>
<li>Always on reliability</li>
<li>Data can be stored geographically close to clients</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>KillrVideo needs to migrate to Cassandra to solve all of these problems. Cassandra uses nodes in a peer-to-peer fashion rather than a single centralized leader/follower database. Cassandra also scales linearly with the number of nodes KillrVideo adds to the system. Cassandra is always on because when some nodes fail, the others pick up the slack. Using Cassandra, KillrVideo can easily locate its nodes geographically to the users' physical location.</p></div>
</div>
</div>
</section>
<section class="slide transition-green" id="courses-DS201-custom-content-quick-wins-challenge-1">
<h2>Installing and Starting Cassandra</h2>

</section>
<section class="slide" id="install-and-start-cassandra">
<h2>Install and Start Cassandra</h2>
<div class="ulist">
<ul>
<li>Install</li>
<li>Start</li>
</ul>
</div>
</section>
<section class="slide" id="cassandra-install-options">
<h2>Cassandra Install Options</h2>
<div class="ulist">
<ul>
<li><p>
DataStax Enterprise with OpsCenter, DevCenter, and Drivers<div class="ulist">
<ul>
<li><a class="bare" href="http://www.datastax.com/download">http://www.datastax.com/download</a></li>
<li>Integrated search and analytics</li>
<li>Free for development</li>
<li>License required for production</li>
</ul>
</div></p></li>
<li><p>
Open Source Cassandra<div class="ulist">
<ul>
<li><a class="bare" href="http://cassandra.apache.org/download">http://cassandra.apache.org/download</a></li>
<li><a class="bare" href="https://github.com/apache/cassandra">https://github.com/apache/cassandra</a></li>
</ul>
</div></p></li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>There are two options when choosing a Cassandra distribution:</p></div>
<div class="olist arabic">
<ol class="arabic">
<li>
DataStax Enterprise&#8482;
</li>
<li>
Apache Cassandra&#8482; open source
</li>
</ol>
</div>
<div class="paragraph"><p>DataStax Enterprise offers several enhancements to Cassandra&#8217;s core features such as security, enhanced testing, management services, analytics, search with Solr, in-memory operation features for lowest latency, etc. You can download DataStax enterprise tinker with it at no cost. Any production use requires licensing from DataStax.</p></div>
<div class="paragraph"><p>Apache Cassandra&#8482; open source is just that, a free distribution where you can look at the source code and also build/run Apache Cassandra&#8482; as well.</p></div>
</div>
</div>
</section>
<section class="slide" id="tarball-install">
<h2>Tarball Install</h2>
<div class="imageblock" style="float: right">
<div class="content">
<img alt="tar ball contents" height="300" src="images/courses/DS201/custom-content/quick-wins/challenge-1/tar-ball-contents.png" />
</div>
</div>
<div class="ulist">
<ul>
<li>Download and extract a simple tar.gz file</li>
<li>Contains Cassandra, configuration, tools, etc.</li>
<li>Cassandra runs directly from one self-contained folder</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>In this course, we will choose the simplest route of install which is to extract a tarball and run Cassandra directly from the target directory.</p></div>
</div>
</div>
</section>
<section class="slide" id="starting-cassandra">
<h2>Starting Cassandra</h2>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>bin/cassandra</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>Cassandra writes several log messages</li>
<li>Look for "state jump to normal"</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>INFO  15:09:21 Node localhost/127.0.0.1 state jump to normal</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Starting Cassandra is straightforward. You will find the executable in the bin/ folder. This folder also hosts several tools we will tinker with through the course.</p></div>
<div class="paragraph"><p>Cassandra will output several log messages. The one we are most interested in is "state jump to normal" which indicates this Cassandra instance is ready to service requests.</p></div>
<div class="paragraph"><p>Once you see this message, simply press enter to get back to your command prompt.</p></div>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-1">
<h2>Exercise 1&#8212;&#8203;Cassandra Install and Start</h2>

</section>
<section class="slide transition-green" id="courses-DS201-custom-content-quick-wins-challenge-2">
<h2>CQL</h2>

</section>
<section class="slide" id="cql-fundamentals">
<h2>CQL Fundamentals</h2>
<div class="ulist">
<ul>
<li>CQL</li>
<li>Keyspaces</li>
<li>Tables</li>
<li>Core datatypes</li>
</ul>
</div>
</section>
<section class="slide" id="cql">
<h2>CQL</h2>
<div class="ulist">
<ul>
<li>Cassandra Query Language (CQL)</li>
<li>Similar to SQL</li>
</ul>
</div>
<div class="listingblock right">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql"><span class="class">SELECT</span> *
<span class="keyword">FROM</span> users;</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Cassandra Query Language (CQL) is a simple data manipulation and query language built to give a familiar environment to those knowing SQL.</p></div>
</div>
</div>
</section>
<section class="slide" id="keyspaces">
<h2>Keyspaces</h2>
<div class="ulist">
<ul>
<li>Top-level namespace/container</li>
<li>Similar to a relational database schema</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql"><span class="class">CREATE</span> KEYSPACE killrvideo
WITH REPLICATION = {
  <span class="string"><span class="delimiter">'</span><span class="content">class</span><span class="delimiter">'</span></span>: <span class="string"><span class="delimiter">'</span><span class="content">SimpleStrategy</span><span class="delimiter">'</span></span>,
  <span class="string"><span class="delimiter">'</span><span class="content">replication_factor</span><span class="delimiter">'</span></span> : <span class="integer">1</span>
};</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>Replication parameters required</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Keyspaces are very similar to database schemas in that they serve as a namespace/wrapper around database objects. When crating a keyspace, we must also set its replication parameters (discussed elsewhere). For now, we will use the most basic settings of SimpleStrategy and a replication factor of one.</p></div>
</div>
</div>
</section>
<section class="slide" id="use">
<h2>USE</h2>
<div class="ulist">
<ul>
<li>USE switches between keyspaces</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql">USE killrvideo;</code></pre>
</div>
</div>
</section>
<section class="slide" id="tables">
<h2>Tables</h2>
<div class="ulist">
<ul>
<li>Keyspaces contain tables</li>
<li>Tables contain data</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql"><span class="class">CREATE</span> <span class="type">TABLE</span> table1 (
  column1 <span class="predefined-type">TEXT</span>,
  column2 <span class="predefined-type">TEXT</span>,
  column3 <span class="predefined-type">INT</span>,
  <span class="directive">PRIMARY</span> <span class="type">KEY</span> (column1)
);

<span class="class">CREATE</span> <span class="type">TABLE</span> users (
  user_id UUID,
  first_name <span class="predefined-type">TEXT</span>,
  last_name <span class="predefined-type">TEXT</span>,
  <span class="directive">PRIMARY</span> <span class="type">KEY</span> (user_id)
);</code></pre>
</div>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>CQL tables look and feel much like SQL tables. There are some key differences we explore later, but for now, thinking of CQL tables as similar to SQL tables is fine.</p></div>
</div>
</div>
</section>
<section class="slide" id="basic-data-types">
<h2>Basic Data Types</h2>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:50%" />
<col style="width:50%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><strong>Type</strong></th>
<th class="tableblock halign-left valign-top"><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">text</p></td>
<td class="tableblock halign-left valign-top"><div><div class="ulist">
<ul>
<li>UTF8 encoded string</li>
<li>varchar is same as text</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><div><div class="ulist">
<ul>
<li>Signed</li>
<li>32 bits</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">timestamp</p></td>
<td class="tableblock halign-left valign-top"><div><div class="ulist">
<ul>
<li>Date and time</li>
<li>64 bit integer</li>
<li>Stores number of seconds since Jan. 1, 1970 00:00:00 GMT</li>
</ul>
</div></div></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Cassandra supports several primitive data types. Most core are text (strings) and ints. You can use VARCHAR in Cassandra, but Cassandra simply replaces it with the <em>text</em> data type. Cassandra does not have fixed-width textual data types such as VARCHAR(50).</p></div>
</div>
</div>
</section>
<section class="slide" id="uuid-timeuuid">
<h2>UUID &amp; TIMEUUID</h2>
<div class="paragraph"><p><strong>Used in place of integer IDs because Cassandra is a distributed database</strong></p></div>
<div class="ulist">
<ul>
<li><p>
Universally Unique Identifier<div class="ulist">
<ul>
<li>Ex: 52b11d6d-16e2-4ee2-b2a9-5ef1e9589328</li>
<li>Generate via uuid()</li>
</ul>
</div></p></li>
<li><p>
TIMEUUID embeds a TIMESTAMP value<div class="ulist">
<ul>
<li>Ex: 1be43390-9fe4-11e3-8d05-425861b86ab6</li>
<li>Sortable</li>
<li>Generate via now()</li>
</ul>
</div></p></li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Cassandra is a distribute database, thus, INSERT commands can arrive at any node. Synching/locking an incrementing integer ID value would prove prohibitive. Thus, we identify records using UUIDs instead. UUIDs enable several nodes to generate non-clashing ID values without any inter-node communication in that regard.</p></div>
<div class="paragraph"><p>Use in places of integer IDs because Cassandra is a distributed database.</p></div>
<div class="paragraph"><p>Value format: hex{8}-hex{4}-hex{4}-hex{4}-hex{12}. UUID is called GUID by some developers.</p></div>
<div class="paragraph"><p>There are different versions/formats of UUIDs. The first digit in the third group of digits indicates the version number. Cassandra&#8217;s TIMEUUID is version 1 and generated using time (60 bits), a clock sequence number (14 bits), and a MAC address (48 bits). Cassandra&#8217;s UUID is version 4 and simply creates unique values.</p></div>
<div class="paragraph"><p>You can order on a TIMEUUID to produce time-ordered data.</p></div>
<div class="paragraph"><p>CQL&#8217;s dateOf() function extracts the time portion of a TIMEUUID.</p></div>
</div>
</div>
</section>
<section class="slide" id="insert">
<h2>INSERT</h2>
<div class="paragraph"><p><strong>Similar to relational syntax</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql"><span class="class">INSERT</span> <span class="class">INTO</span> users (user_id, first_name, last_name)
<span class="keyword">VALUES</span> (uuid(), <span class="string"><span class="delimiter">'</span><span class="content">Joseph</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">Chu</span><span class="delimiter">'</span></span>);</code></pre>
</div>
</div>
</section>
<section class="slide" id="select">
<h2>SELECT</h2>
<div class="paragraph"><p><strong>Similar to relational syntax</strong></p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql"><span class="class">SELECT</span> *
<span class="keyword">FROM</span> users;

<span class="class">SELECT</span> first_name, last_name
<span class="keyword">FROM</span> users;

<span class="class">SELECT</span> *
<span class="keyword">FROM</span> users
<span class="keyword">WHERE</span> user_id = <span class="integer">4</span>b516be3-ddf0<span class="integer">-4</span>c43-bab6-b91d674b64a5;</code></pre>
</div>
</div>
</section>
<section class="slide" id="copy">
<h2>COPY</h2>
<div class="ulist">
<ul>
<li>Imports/exports CSV (comma-separated values)</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql">COPY table1 (column1, column2, column3) <span class="keyword">FROM</span> <span class="string"><span class="delimiter">'</span><span class="content">table1data.csv</span><span class="delimiter">'</span></span>;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>Header parameter skips the first line in the file</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql">COPY table1 (column1, column2, column3) <span class="keyword">FROM</span> <span class="string"><span class="delimiter">'</span><span class="content">table1data.csv</span><span class="delimiter">'</span></span>
WITH HEADER=<span class="predefined-constant">true</span>;</code></pre>
</div>
</div>
</section>
<section class="slide" id="there-s-more">
<h2>There&#8217;s more!</h2>
<div class="ulist">
<ul>
<li>See our DS220 Data Modeling course for a thorough CQL guide</li>
<li><a class="bare" href="http://academy.datastax.com">http://academy.datastax.com</a></li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-2">
<h2>Exercise 2&#8212;&#8203;CQL</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-partitions">
<h2>Partitions</h2>

</section>
<section class="slide" id="tables-2">
<h2>Tables</h2>
<div class="paragraph" id="tabl"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Animation 1: Let&#8217;s start with a basic typical relational table example. Here we create a table to store KillrVideo user information.</p></div>
<div class="paragraph"><p>Animation 2: Inserting a single record into this table is hopefully familiar to you.</p></div>
<div class="paragraph"><p>Animation 3: Inserting several records into this table hopefully also looks familiar.</p></div>
<div class="paragraph"><p>Animation 4: [No commentary. Table moves to center for next slide.]</p></div>
</div>
</div>
</section>
<section class="slide" id="partitions">
<h2>Partitions</h2>
<div class="paragraph" id="parts"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Cassandra physically stores the data differently than relational databases.</p></div>
<div class="paragraph"><p>Animation 1: Since we query the data by state, we structure our Cassandra data model so that users in the same state are co-located on disk. We call these groupings <em>partitions</em>.</p></div>
<div class="paragraph"><p>Animation 2: A <em>partition key</em> uniquely identifies its partition. Notice the partition keys here are the US state codes.</p></div>
<div class="paragraph"><p>Animation 3: However, Cassandra doesn&#8217;t literally key off the partition key value. Instead, Cassandra references each partition by its token, which is a hash of the partition key value. The partitioner is responsible for hashing.</p></div>
<div class="paragraph"><p>Animation 4: Notice the partitioner hashes each partition key value to produce a corresponding token. These values appear random, but really are deterministic. The partitioner will produce the same token given the same value multiple times.</p></div>
<div class="paragraph"><p>Animation 5: The CQL PRIMARY KEY clause determines the partition key. Thus, to partition using US states, we write PRIMARY KEY(state).</p></div>
<div class="paragraph"><p>Animation 6: However, a state code alone is not enough to produce a unique primary key value, so we also add the video&#8217;s id to the primary key as well. Notice that we surrounded  the <em>state</em> column within its own set of parenthesis. These parenthesis indicate the partition key, whereas id is a <em>clustering column</em>.</p></div>
<div class="paragraph"><p>We discuss clustering columns elsewhere, but at this point, their meaning is not significant.</p></div>
<div class="paragraph"><p>Animation 7: Partitions are atomic units of storage, meaning, Cassandra stores a complete partition on a single node.</p></div>
<div class="paragraph"><p>Animation 8: Depending on token settings (explored elsewhere), Cassandra distributes each partition to the node responsible for storing it.</p></div>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-3">
<h2>Exercise 3&#8212;&#8203;Partitions</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-clustering-columns">
<h2>Clustering Columns</h2>

</section>
<section class="slide" id="clustering-columns">
<h2>Clustering Columns</h2>
<div class="paragraph" id="prt"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Here we focus on one partition of KillrVideo user data. We partition users by their US state. These users live in Texas.</p></div>
<div class="paragraph"><p>Animation 1: This PRIMARY KEY clause places the state column in the first set of parenthesis which partitions users by their state. The city column follows after the set of parenthesis making a clustering column.</p></div>
<div class="paragraph"><p>Animation 2: Cassandra physically stores the data on disk within the partition sorted by the clustering columns. Notice the rows sort on city.</p></div>
<div class="paragraph"><p>Animation 3: If you want to store the users sorted by their name, you would have to create a table having the PRIMARY KEY cluster by user&#8217;s name instead of their state.</p></div>
<div class="paragraph"><p>Animation 4: This slight change merely causes Cassandra to store the users sorted by their name rather than their city.</p></div>
<div class="paragraph"><p>Animation 5: We change the PRIMARY KEY to first cluster by city and then by name.</p></div>
<div class="paragraph"><p>Animation 6: On disk, Cassandra stores the data sorted first by the users&#8217;s city. This is similar to ordering by multiple columns.</p></div>
<div class="paragraph"><p>Animation 7: Within each city, Cassandra then stores the data sorted by name.</p></div>
<div class="paragraph"><p>Animation 8: No matter what we partition and cluster by, we must always add an identifying field to the end of the primary key to provide uniqueness. Technically, in this case, this would sort users in the same city with the same name by their ID values, but there is only one row per such grouping.</p></div>
<div class="paragraph"><p>Since Cassandra stores rows sorted by their clustering columns, retrieving that data sorted is simply a matter of seeking the disk head once and streaming the result. Note it is also possible to reverse the order using an ORDER BY clause, but that is it. You cannot use ORDER BY to retrieve results ordered by something other than that specified by the clustering columns.</p></div>
</div>
</div>
</section>
<section class="slide" id="querying-clustering-columns">
<h2>Querying Clustering Columns</h2>
<div class="ulist">
<ul>
<li>You must first provide a partition key</li>
<li>Clustering columns can follow thereafter</li>
<li>You can perform either equality (=) or range queries (&lt;, &gt;) on clustering columns</li>
<li>All equality comparisons must come before inequality comparisons</li>
<li>Since data is sorted on disk, range searches are a binary search followed by a linear read</li>
</ul>
</div>
</section>
<section class="slide" id="changing-default-ordering">
<h2>Changing Default Ordering</h2>
<div class="ulist">
<ul>
<li>Clustering columns default ascending order</li>
<li>Change ordering direction via WITH CLUSTERING ORDER BY</li>
<li>Must include all columns including and up to the columns you wish to order descending</li>
<li>For example, we exclude 'id' below and assume ASC</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="sql language-sql"><span class="class">CREATE</span> <span class="type">TABLE</span> users (
  state <span class="predefined-type">text</span>,
  city <span class="predefined-type">text</span>,
  name <span class="predefined-type">text</span>,
  id uuid,
  <span class="directive">PRIMARY</span> <span class="type">KEY</span>((state), city, name, id))
  WITH CLUSTERING <span class="keyword">ORDER</span> <span class="keyword">BY</span>(city <span class="directive">DESC</span>, name <span class="directive">ASC</span>);</code></pre>
</div>
</div>
</section>
<section class="slide" id="allow-filtering">
<h2>Allow Filtering</h2>
<div class="ulist">
<ul>
<li>ALLOW FILTERING relaxes the querying on partition key constraint</li>
<li>You can then query on just clustering columns</li>
<li>Causes Cassandra to scan all partitions in the table</li>
<li><p>
Don&#8217;t use it<div class="ulist">
<ul>
<li>Unless you really have to</li>
<li>Best on small data sets</li>
<li>But still, don&#8217;t use it, seriously</li>
</ul>
</div></p></li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-4">
<h2>Exercise 4&#8212;&#8203;Clustering Columns</h2>

</section>
<section class="slide transition-green" id="courses-DS201-custom-content-drivers">
<h2>Connecting Your Application</h2>

</section>
<section class="slide" id="drivers">
<h2>Drivers</h2>
<div class="ulist">
<ul>
<li>Drivers easily connect your application to your Cassandra database</li>
<li><p>
Driver languages:<div class="ulist">
<ul>
<li>Java</li>
<li>Python</li>
<li>C#</li>
<li>C++</li>
<li>Many more: <a class="bare" href="http://www.planetcassandra.org/client-drivers-tools/">http://www.planetcassandra.org/client-drivers-tools/</a></li>
</ul>
</div></p></li>
</ul>
</div>
</section>
<section class="slide" id="drivers-api">
<h2>Drivers API</h2>
<div class="ulist">
<ul>
<li>API is similar between languages</li>
<li>Policies are the same (load balancing, rebalancing, etc.)</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code># Python
cluster = Cluster()
session = cluster.connect('killrvideo')
result = session.execute("&lt;query&gt;")[0]

// Java
Cluster cluster = Cluster.builder().addContactPoint("127.0.0.1").build();
Session session = cluster.connect("killrvideo");
ResultSet results = session.execute("&lt;query&gt;");

// Ruby
cluster = Cassandra.cluster
session  = cluster.connect('killrvideo')
session.execute("&lt;query&gt;")</code></pre>
</div>
</div>
</section>
<section class="slide" id="setup">
<h2>Setup</h2>
<div class="ulist">
<ul>
<li>We will use Python</li>
<li>Create a cluster object</li>
<li>Use the cluster to obtain a session</li>
<li>Session manages connections to the cluster</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="python language-python"><span class="comment"># Connect to the cluster and keyspace &quot;killrvideo&quot;</span>
<span class="keyword">from</span> <span class="include">cassandra.cluster</span> <span class="keyword">import</span> <span class="include">Cluster</span>
cluster = Cluster()
session = cluster.connect(<span class="string"><span class="delimiter">'</span><span class="content">killrvideo</span><span class="delimiter">'</span></span>)</code></pre>
</div>
</div>
</section>
<section class="slide" id="insert-2">
<h2>INSERT</h2>
<div class="ulist">
<ul>
<li>Insert a user</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="python language-python">session.execute(<span class="string"><span class="delimiter">&quot;&quot;&quot;</span><span class="content">
</span><span class="content">INSERT INTO users (userid, created_date, email, firstname, lastname)</span><span class="content">
</span><span class="content">VALUES (14c532ac-f5ae-479a-9d0a-36604732e01d, '2013-01-01 00:00:00', 'patrick@example.com', 'Patrick', 'McFadin')</span><span class="content">
</span><span class="delimiter">&quot;&quot;&quot;</span></span>)</code></pre>
</div>
</div>
</section>
<section class="slide" id="select-2">
<h2>SELECT</h2>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code class="python language-python"><span class="comment"># Use select to get the user we just entered</span>
result = session.execute(<span class="string"><span class="delimiter">&quot;</span><span class="content">SELECT * FROM users WHERE userid=14c532ac-f5ae-479a-9d0a-36604732e01d</span><span class="delimiter">&quot;</span></span>)[<span class="integer">0</span>]
<span class="keyword">print</span> result.firstname, result.lastname, result.email</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>The output:</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre><code>Patrick McFadin patrick@example.com</code></pre>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-5">
<h2>Exercise 5&#8212;&#8203;Drivers</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-node-architecture-node">
<h2>Node</h2>

</section>
<section class="slide" id="node">
<h2>Node</h2>
<div class="paragraph" id="ndrynde"><p><strong>Cassandra Node</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>A Cassandra node is a single Cassandra instance. It can serve as a database by itself, but we will soon see that there is strength in numbers.</p></div>
<div class="paragraph"><p>Animation 1: Cassandra is a Java application executing on the Java virtual machine.</p></div>
<div class="paragraph"><p>Animation 2: You can deploy Cassandra to the cloud.</p></div>
<div class="paragraph"><p>Animation 3: You can deploy Cassandra to your own hardware as well.</p></div>
<div class="paragraph"><p>Animation 4: Cassandra requires direct-attached storage. Do not use Cassandra with any type of network-attached storage.</p></div>
<div class="paragraph"><p>Animation 5: [Images fade out.]</p></div>
<div class="paragraph"><p>Animation 6: Both Cassandra read and write requests are simple. Cassandra acts as a huge hashtable storing partitions keyed off their partition key.</p></div>
<div class="paragraph"><p>Animation 7: Here we see partition data with a token value of 55 stored inside this Cassandra node.</p></div>
<div class="paragraph"><p>Animation 8: Here a request for the partition with a token value of 22 arrives.</p></div>
<div class="paragraph"><p>Animation 9: Cassandra quickly locates the partition using some basic hashing principles discussed elewhere.</p></div>
<div class="paragraph"><p>Animation 10: And returns the data</p></div>
<div class="paragraph"><p>Animation 11: A typical Cassandra node can handle 3,000 to 5,000 such request per second per core. We recommend a rough max of one to three terabytes of data per node.</p></div>
</div>
</div>
</section>
<section class="slide" id="nodetool">
<h2>Nodetool</h2>
<div class="paragraph"><p><strong>Node management</strong></p></div>
<div class="ulist">
<ul>
<li>Located in the <code>bin/ folder</code></li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>bin/nodetool help</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>Management tool with several sub commands</li>
</ul>
</div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:50%" />
<col style="width:50%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"><strong>Command</strong></th>
<th class="tableblock halign-left valign-top"><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">help</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lists all possible sub commands</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">info</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Current node settings and stats</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">status</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reports basic node health information</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>Many more</li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-6">
<h2>Exercise 6&#8212;&#8203;Node</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-node-architecture-ring">
<h2>Ring</h2>

</section>
<section class="slide" id="the-pressures-of-scale">
<h2>The Pressures of Scale</h2>
<div class="paragraph" id="overloadednode"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Here we have a single yet happy Cassandra node.</p></div>
<div class="paragraph"><p>Animation 1: As long as this single node receives fewer write/read requests than it can handle, life is good.</p></div>
<div class="paragraph"><p>Animation 2: However, as soon as the number of requests passes this threshold, things get scary. The node can either lag or crash depending on circumstances.</p></div>
</div>
</div>
</section>
<section class="slide" id="the-ring">
<h2>The Ring</h2>
<div class="paragraph" id="thering"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>So what we do in Cassandra is add more nodes, each node taking a slice of the workload. The requests no longer outnumber any node&#8217;s ability to serve them. Notice we structured the nodes in a ring-like fashion.</p></div>
<div class="paragraph"><p>Animation 1: [Ring moves up.]</p></div>
<div class="paragraph"><p>Animation 2: Having a ring however poses a question. When a request to store a partition arrives, how do we decide which node will handle the request and/or store the data?</p></div>
<div class="paragraph"><p>Animation 3: It turns out that ANY node in the ring can service the request because all nodes are peers. Cassandra has zero concept of a leader/follower relationship. The node chosen to handle the request is called the <em>coordinator</em>. Although the top-left node acts as the coordinator, we must still determine which node will actually store the data.</p></div>
<div class="paragraph"><p>Animation 4: We do this by having each node take a slice of the token range value. The token range in this case is 0-99. Notice the top node stores all partitions whose token falls in the range of 88-0. The next node clockwise stores partitions with token values falling in the range of 1-13, and so on.</p></div>
<div class="paragraph"><p>Animation 5: Since the bottom node is responsible for partition tokens from 51 to 63 (purple range), the coordinator forwards the data to that node since this partition has a token value of 59.</p></div>
<div class="paragraph"><p>Animation 6: [Coordinator forwards the data.]</p></div>
<div class="paragraph"><p>Note: ANY node can act as the coordinator. All nodes are aware of the ring token value distribution, and all nodes (should be configured to) use the same partitioner. Thus any node can determine which nodes store which data. There is no leader node in Cassandra.</p></div>
</div>
</div>
</section>
<section class="slide" id="the-range">
<h2>The Range</h2>
<div class="paragraph" id="fullrng"><p>100 values is just not enough.</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>We often consider rings with a token range of 100 values, however, chances are you will store more than 100 partitions in your database.</p></div>
<div class="paragraph"><p>Animation 1: The actual token range runs from -2^63 to 2^63 - 1. This is a large enough range to store your data.</p></div>
</div>
</div>
</section>
<section class="slide" id="token-value-distribution">
<h2>Token Value Distribution</h2>
<div class="paragraph" id="csthsh"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>The partitioner is responsible for hashing the partition key to a token value. Some partitioners are better than others. A poor partitioner does not give an even spread of token values around the ring.</p></div>
<div class="paragraph"><p>Animation 1: This partitioner does not have an even distribution in its token values, so most of the partitions end up on the top and bottom nodes putting undue stress upon them. The other two nodes are severely underutilized.</p></div>
<div class="paragraph"><p>Animation 2: Cassandra uses a Mumur3Partitioner, which spreads its token values uniformly around the ring.</p></div>
</div>
</div>
</section>
<section class="slide" id="joining-the-cluster">
<h2>Joining the Cluster</h2>
<div class="ulist">
<ul>
<li>Nodes join the cluster by communicating with any node</li>
<li>Cassandra finds these <em>seed nodes</em> list of possible nodes in cassandra.yaml</li>
<li>Seed nodes communicate cluster topology to the joining node</li>
<li>Once the new node joins the cluster, all nodes are peers</li>
</ul>
</div>
</section>
<section class="slide" id="drivers-2">
<h2>Drivers</h2>
<div class="ulist">
<ul>
<li>Drivers intelligently choose which node would best coordinate a request</li>
<li>Per-query basis:</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>ResultSet results = session.execute("&lt;query&gt;");</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>TokenAwarePolicy - driver chooses node which contains the data</li>
<li>RoundRobinPolicy - driver round robins the ring</li>
<li>DCAwareRoundRobinPolicy - driver round robins the target data center</li>
</ul>
</div>
</section>
<section class="slide" id="scale">
<h2>Scale</h2>
<div class="paragraph"><p><strong>Cassandra scales at a near-linear rate</strong></p></div>
<div class="paragraph"><p><span class="image"><img alt="write-mostly-workload" height="600px" src="images/cassandra/internals/node-architecture/ring/write-mostly-workload.png" /></span></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>END POINT, a third party, tested several big-data databases and produced the following paper: <a class="bare" href="http://www.datastax.com/wp-content/themes/datastax-2014-08/files/NoSQL_Benchmarks_EndPoint.pdf">http://www.datastax.com/wp-content/themes/datastax-2014-08/files/NoSQL_Benchmarks_EndPoint.pdf</a></p></div>
<div class="paragraph"><p>Video: <a class="bare" href="http://youtu.be/ioZugO2MEAk?t=59m40s">http://youtu.be/ioZugO2MEAk?t=59m40s</a></p></div>
<div class="paragraph"><p>Here we see that Cassandra dominates. Read the entire paper for even more awesome details.</p></div>
</div>
</div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Cassandra scales at a near-linear rate</strong></p></div>
<div class="paragraph"><p><span class="image"><img alt="read-mostly-workload" height="600px" src="images/cassandra/internals/node-architecture/ring/read-mostly-workload.png" /></span></p></div>
<div style="page-break-after: always"></div>
<div class="paragraph"><p><strong>Cassandra scales at a near-linear rate</strong></p></div>
<div class="paragraph"><p><span class="image"><img alt="read-write-mix" height="600px" src="images/cassandra/internals/node-architecture/ring/read-write-mix.png" /></span></p></div>
</section>
<section class="slide" id="horizontal-vs-vertical-scaling">
<h2>Horizontal vs Vertical Scaling</h2>
<div class="ulist">
<ul>
<li>Vertical scaling requires one large expensive machine</li>
<li>Horizontal scaling requires multiple less-expensive commodity hardware</li>
</ul>
</div>
<div class="paragraph"><p><span class="image"><img alt="horizontal-scaling" src="images/cassandra/internals/node-architecture/ring/horizontal-scaling.svg" /></span></p></div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-7">
<h2>Exercise 7&#8212;&#8203;Ring</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-peer-to-peer">
<h2>Peer to Peer</h2>

</section>
<section class="slide" id="leader-follower">
<h2>Leader-Follower</h2>
<div class="paragraph" id="mrslv"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Here&#8217;s a typical client-sever simple application scenario.</p></div>
<div class="paragraph"><p>Animation 1: However, storing your data on a single server lends your application to stop responding due to this single point of failure. So we add some redundant servers setting the original as the leader. The leader serves requests and also updates the follower&#8217;s copies as time progresses. If the leader fails, then the system can elect a follower as a new leader.</p></div>
<div class="paragraph"><p>Animation 2: Eventually as your company progresses, you outgrow the capacity of just one server. You can only scale your hardware up so far due to physical CPU limits or financial limits. So you shard your data across multiple leader servers.</p></div>
<div class="paragraph"><p>Animation 3: However, now that we shard, we must place a routing service at the head of this to determine which leaders store which pieces of data.</p></div>
<div class="paragraph"><p>Animation 4: When a request comes into this system, the router determines which shard owns that data.</p></div>
<div class="paragraph"><p>Animation 5: However, if that server goes down&#8230;&#8203;</p></div>
<div class="paragraph"><p>Animation 6: We spend precious time determining it&#8217;s down before electing a new leader.</p></div>
<div class="paragraph"><p>Animation 7: Eventually we elect a new leader.</p></div>
<div class="paragraph"><p>Animation 8: [Resetting for next illustration.] Another fault in this architecture is that it is brittle.</p></div>
<div class="paragraph"><p>Animation 9: What happens when we have a network partition? (A switch or router fails.) Both groups of servers can communicate with each other, but they cannot communicate with other servers across the groups.</p></div>
<div class="paragraph"><p>Animation 10: Both halves of the partition elect new leaders and start accepting requests. This is called a split-brain scenario. Multiple leaders accepting updates for the same data causes corruption.</p></div>
</div>
</div>
</section>
<section class="slide" id="peer-to-peer">
<h2>Peer-to-Peer</h2>
<div class="paragraph" id="prtopr"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>In contrast, Cassandra has no (as in zero, nada, noooooo) leader-follower architecture built into it. Each node can handle reads/writes independently of the others.</p></div>
<div class="paragraph"><p>Animation 1: For example, here are three nodes each storing a copy of our data.</p></div>
<div class="paragraph"><p>Animation 2: When a request comes in to retrieve the data, any of the three nodes can service that request.</p></div>
<div class="paragraph"><p>Animation 3: Any node in the cluster can also act as the coordinator as well. No single node is a leader of the cluster.</p></div>
<div class="paragraph"><p>Animation 4: [Request graphics clear.]</p></div>
<div class="paragraph"><p>Animation 5: Cassandra handles network partitions cleanly as well.</p></div>
<div class="paragraph"><p>Animation 6: A request on the left half of the partition is handled by that half.</p></div>
<div class="paragraph"><p>Animation 7: A request on the right half does the same.</p></div>
<div class="paragraph"><p>When the dust settles and the network partition is resolved, Cassandra uses the last write as the most current data. You can tune how much fault tolerance you&#8217;re willing to put up with on a per-query basis. We discuss this elsewhere.</p></div>
</div>
</div>
</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-vnodes">
<h2>VNodes</h2>

</section>
<section class="slide" id="regular-token-range-assignment">
<h2>Regular Token Range Assignment</h2>
<div class="paragraph" id="drawing"><p><strong>Token assignment is not always an even spread</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>In a perfect world, we would not have to decomission/recommision nodes. But, we are not in a perfect world and adding/removing nodes to your cluster is common. That said, with normal token range assignments, you have to ensure that your token assignments are evenly spread. Adding/removing nodes to your cluster can also make the system unbalanced for a time, and it also requires nodes with existing data to stream the data to the new node(s).</p></div>
<div class="paragraph"><p>For example, here is an unbalanced cluster. Notice the yellow node owns half of the token range.</p></div>
<div class="paragraph"><p>Animation 1: Here we see smaller circles representing partitions. A good partitioner evenly spreads the partition token assignments. The yellow node has double the number of partitions as the other two nodes.</p></div>
<div class="paragraph"><p>Animation 2: We wish to add a new node to the cluster.</p></div>
<div class="paragraph"><p>Animation 3: Ideally the new node splits the yellow node&#8217;s token range assignment in half.</p></div>
<div class="paragraph"><p>Animation 4: Notice the new node does just that.</p></div>
<div class="paragraph"><p>Animation 5: Notice half the partitions in the yellow node fall into this light-blue token range, and thus Cassandra must now move them to the new node.</p></div>
<div class="paragraph"><p>Animation 6: The yellow node streams the pertinent replicas to the new nodes. Unfortunately this puts strain on the yellow node.</p></div>
</div>
</div>
</section>
<section class="slide" id="vnodes">
<h2>VNodes</h2>
<div class="paragraph" id="vndes"><p><strong>Each node has several tokens it manages</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Cassandra&#8217;s vnode feature helps mitigate this problem by having each physical node act more like several smaller virtual nodes. Let&#8217;s examine how this works.</p></div>
<div class="paragraph"><p>Animation 1: Each node is now responsible for several smaller slices of the ring instead of just one large slice.</p></div>
<div class="paragraph"><p>Animation 2: Notice, with a consistent hash, all three nodes have roughly the same amount of data. That&#8217;s because each node&#8217;s smaller portions of the ring add up to one-third of the ring instead of one-half plus two one-fourth sections as we saw in the previous slide. This isn&#8217;t such a big win so far however because in the previous example with just three nodes, we could have split our range into even thirds instead.</p></div>
<div class="paragraph"><p>Animation 3: One of the real wins with vnodes, however, is when a node wants to join or leave this cluster. Here the blue node wants to join the cluster as it did on the previous slide.</p></div>
<div class="paragraph"><p>Animation 4: Notice the token assignments again change, however, instead of the new node simply taking over one node&#8217;s token range, the new node takes over portions of every node&#8217;s range.</p></div>
<div class="paragraph"><p>Animation 5: Notice our partition colors for the blue node change to blue themselves. Now every node has some data that it must stream to the new node.</p></div>
<div class="paragraph"><p>Animation 6: Each node streams its data in parallel with the other nodes. This makes bootstrapping a new node into the cluster take much less time and takes the burden of doing this streaming off any single node.</p></div>
</div>
</div>
</section>
<section class="slide" id="vnode-details">
<h2>VNode Details</h2>
<div class="ulist">
<ul>
<li>Adding/removing nodes with vnodes should not make the cluster unbalanced</li>
<li>By default, each node has 256 vnodes</li>
<li>VNodes automate token range assignment</li>
</ul>
</div>
</section>
<section class="slide" id="configuration">
<h2>Configuration</h2>
<div class="ulist">
<ul>
<li>Configure vnode settings in cassandra.yaml</li>
<li>num_tokens</li>
<li>Value greater than one turns on vnodes</li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-8">
<h2>Exercise 8&#8212;&#8203;VNodes</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-gossip">
<h2>Gossip</h2>

</section>
<section class="slide" id="gossip">
<h2>Gossip</h2>
<div class="paragraph"><p><span class="image"><img alt="gossip" src="images/cassandra/internals/distributed-architecture/gossip/gossip.jpg" /></span></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Understanding Gossip video: <a class="bare" href="https://www.youtube.com/watch?v=FuP1Fvrv6ZQ">https://www.youtube.com/watch?v=FuP1Fvrv6ZQ</a></p></div>
<div class="paragraph"><p>Cassandra Wiki on Gossip: <a class="bare" href="https://wiki.apache.org/cassandra/ArchitectureGossip">https://wiki.apache.org/cassandra/ArchitectureGossip</a></p></div>
</div>
</div>
</section>
<section class="slide" id="epidemic">
<h2>Epidemic</h2>
<div class="paragraph" id="gspr"><p><strong>Gossip is an epidemic protocol that spreads through the cluster.</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Gossip is a broadcast protocol for disseminating data. No centralized server holds the cluster information, but instead, the peers spread this information among themselves maintaining only the latest information automatically.</p></div>
<div class="paragraph"><p>Animation 1: Here&#8217;s our first node that has some information it wants to share.</p></div>
<div class="paragraph"><p>Animation 2: The first node picks the bottom node and shares that information.</p></div>
<div class="paragraph"><p>Animation 3: That second node then shares that information with the left node. The first node also shares the information with the node at the upper right.</p></div>
<div class="paragraph"><p>Animation 4: In the next round, all the nodes with the information also share it with other nodes. Now the entire cluster knows that information. The information in this case spreads out in a polynomial fashion.</p></div>
<div class="paragraph"><p>A node can gossip with as many nodes as we like during each round. Nodes don&#8217;t necessarily gossip in such an ordered fashion, but instead pick nodes based on some criteria we will discuss.</p></div>
</div>
</div>
</section>
<section class="slide" id="choosing-a-gossip-node">
<h2>Choosing a Gossip Node</h2>
<div class="ulist">
<ul>
<li>Each node initiates a gossip round every second</li>
<li>Picks one to three nodes to gossip with</li>
<li>Nodes can gossip with ANY other node in the cluster</li>
<li>Probabilistically (slightly favor) seed and downed nodes</li>
<li>Nodes do not track which nodes they gossiped with prior</li>
<li>Reliably and efficiently spreads node metadata through the cluster</li>
<li>Fault tolerant&#8212;&#8203;continues to spread when nodes fail</li>
</ul>
</div>
</section>
<section class="slide" id="what-to-gossip">
<h2>What to Gossip?</h2>
<div class="paragraph" id="whtgsp"><p><strong>Cluster Metadata</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Let&#8217;s look at what data gossip spreads through the cluster. Gossip spreads only node metatdata (not client data).</p></div>
<div class="paragraph"><p>Animation 1: All nodes are similar, so we will focus on only one node.</p></div>
<div class="paragraph"><p>Animation 2: Each node has an overarching data structure called an endpoint state. This essentially stores all the gossip state information for a single node (endpoint).</p></div>
<div class="paragraph"><p>Animation 3: The endpoint state nests another data structure called the heartbeat state.</p></div>
<div class="paragraph"><p>Animation 4: The heartbeat state tracks two values. The first is the generation, which is a timestamp of when the node bootstrapped.</p></div>
<div class="paragraph"><p>Animation 5: The version is a simple integer. Each node increments its value every second. Heartbeat values incrementing then spreading through the cluster allow nodes to make assumptions as to whether other nodes are up or not.</p></div>
<div class="paragraph"><p>Animation 6: Endpoint states nest a second data structure called the application state. The application state stores the metadata for this node. The application state is the data about the node gossip spreads throughout the cluster.</p></div>
<div class="paragraph"><p>Animation 7: One piece of metadata is the STATUS. STATUS can have one of several values: BOOTSTRAP (node is coming online), NORMAL, LEAVING/LEFT (you are decommissioning a node), REMOVING/REMOVE (you are removing a node that you can&#8217;t physically access). Nodes declare their own status. Although each nodes FailureDetector will determine if a peer appears to be up/down, nodes do not gossip these assumptions about peers.</p></div>
<div class="paragraph"><p>Animation 8: DC is for a node&#8217;s data center.</p></div>
<div class="paragraph"><p>Animation 9: Rack is the node&#8217;s rack.</p></div>
<div class="paragraph"><p>Animation 10: Schema changes as any schemas in the node are changed.</p></div>
<div class="paragraph"><p>Animation 11: Load is disk space usage.</p></div>
<div class="paragraph"><p>Animation 12: Severity is a heuristic of IO pressure on the node.</p></div>
<div class="paragraph"><p>Animation 13: Etc.</p></div>
</div>
</div>
</section>
<section class="slide" id="node-gossip-communication">
<h2>Node Gossip Communication</h2>
<div class="paragraph" id="snc"><p><strong>Let&#8217;s look at a single gossip exchange.</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Gossip is a simple messaging protocol. Here we will examine a single gossip exchange between two nodes.</p></div>
<div class="paragraph"><p>Animation 1: We will examine an exchange between nodes A and C.</p></div>
<div class="paragraph"><p>Animation 2: Here we see each node storing three endpoint states, one for each node in the cluster including itself. (We eliminated our fourth node from the discussion for simplicity.) EP is short for endpoint, indicating the IP address of the node that this endpoint state data belongs to. HB is heartbeat state, the first number being the generation and second number being the version (the heartbeat). Although each endpoint state stores several different values in its application state, we will only examine one in this demonstration: LOAD. Note that any of these endpoint states could be for the current node, but that doesn&#8217;t matter to gossip.</p></div>
<div class="paragraph"><p>Animation 3: [Message arrow appears.]</p></div>
<div class="paragraph"><p>Animation 4: The left node initiates the gossip via a SYN message to the right node. This message stores a simple digest of information for the receiving node to examine.</p></div>
<div class="paragraph"><p>Animation 5: Each digest stores the endpoint address, generation, and version (complete heartbeat) for each node that this node has information about.</p></div>
<div class="paragraph"><p>Animation 6: The first digest is for node 127.0.0.1. The SYN message store this node&#8217;s endpoint/heartbeat information in the digest.</p></div>
<div class="paragraph"><p>Animation 7: Same for node 127.0.0.2.</p></div>
<div class="paragraph"><p>Animation 8: Same for node 127.0.0.3.</p></div>
<div class="paragraph"><p>Animation 9: The left node then transports the SYN message to the right node.</p></div>
<div class="paragraph"><p>Animation 10: The receiving node compares what it currently knows to what is in the SYN. It sees that the heartbeat generations match but the heartbeat versions do not. The information this node has about node 127.0.0.1 is stale because its heartbeat version is 15 which is less than the version that the initiating node has of 20. This node needs the details about this updated information from the sending node.</p></div>
<div class="paragraph"><p>Animation 11: The receiving node constructs an ACK message in reply to the sending node&#8217;s SYN. Similar to the SYN, the ACK stores digest information as well.</p></div>
<div class="paragraph"><p>Animation 12: The receiving node stores its digest information about node 127.0.0.1 in the ACK. In this way, the receiving node tells the sending node that it knows all information about node 127.0.0.1 up to version 15 and it needs the updated information about node 127.0.0.1 from the sending node.</p></div>
<div class="paragraph"><p>Animation 13: In comparing values for node 127.0.0.2, the receiving node sees that it has more up to date data than the sending node. Heartbeat version 50 is greater than 40.</p></div>
<div class="paragraph"><p>Animation 14: The receiving node packs the updated information into the ACK message instead of a simple digest for node 127.0.0.2.</p></div>
<div class="paragraph"><p>Animation 15: For node 127.0.0.3, the receiving node sees its data is out of date.</p></div>
<div class="paragraph"><p>Animation 16: So it places a digest concerning 127.0.0.3 into the ACK message, thus requesting the latest information from the sending node.</p></div>
<div class="paragraph"><p>Animation 17: The receiving node sends the ACK back to the initiator.</p></div>
<div class="paragraph"><p>Animation 18: The initiator sees that the second node needs updated information for nodes 127.0.0.1 and 127.0.0.2.</p></div>
<div class="paragraph"><p>Animation 19: The initiator creates an ACK2 in response to the second node. The initiator places the updated values inside the ACK2.</p></div>
<div class="paragraph"><p>Animation 20: The initiator also sees that the second node responded with updated data for node 127.0.0.2.</p></div>
<div class="paragraph"><p>Animation 21: The initiator updates its data for node 127.0.0.2.</p></div>
<div class="paragraph"><p>Animation 22: The ACK completes, and the initiator sends the ACK2 message to the second node.</p></div>
<div class="paragraph"><p>Animation 23: The second node sees the updated information it requested in the ACK2 message.</p></div>
<div class="paragraph"><p>Animation 24: The second node updates its data accordingly.</p></div>
<div class="paragraph"><p>Animation 25: The gossip round completes, and the two nodes are now in sync.</p></div>
</div>
</div>
</section>
<section class="slide" id="network-traffic">
<h2>Network Traffic</h2>
<div class="ulist">
<ul>
<li>Constant rate (trickle) of network traffic</li>
<li>Minimal compared to data streaming, hints</li>
<li>Doesn&#8217;t cause network spikes</li>
<li>However, gossip indicating that a node is joining the cluster or back online causes other nodes to stream data to the new node</li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-9">
<h2>Exercise 9&#8212;&#8203;Gossip</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-snitches">
<h2>Snitch</h2>

</section>
<section class="slide" id="snitch">
<h2>Snitch</h2>
<div class="paragraph"><p><span class="image" style="float: right"><img alt="snitch" src="images/cassandra/internals/distributed-architecture/snitches/snitch.jpg" /></span></p></div>
<div class="ulist">
<ul>
<li>Nothing to do with Harry Potter</li>
<li>Determines/declares each node&#8217;s rack and data center</li>
<li>The "topology" of the cluster</li>
<li>Several different types of snitches</li>
<li>Configured in cassandra.yaml</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>endpoint_snitch: SimpleSnitch</code></pre>
</div>
</div>
</section>
<section class="slide" id="snitches">
<h2>Snitches</h2>
<div class="paragraph"><p><strong>There are two main groups of snitches.</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:50%" />
<col style="width:50%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Regular</th>
<th class="tableblock halign-left valign-top">Cloud Based</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SimpleSnitch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ec2Snitch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PropertyFileSnitch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ec2MultiRegionSnitch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GossipingPropertyFileSnitch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">GoogleCloudSnitch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DynamicSnitch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">CloudstackSnitch</p></td>
</tr>
</tbody>
</table>
</section>
<section class="slide" id="simple-snitch">
<h2>Simple Snitch</h2>
<div class="ulist">
<ul>
<li>Places all nodes in the same data center and rack</li>
<li>Default snitch</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>public class SimpleSnitch extends AbstractEndpointSnitch
{
   public String getRack(InetAddress endpoint)
   {
       return "rack1";
   }

   public String getDatacenter(InetAddress endpoint)
   {
       return "datacenter1";
   }
}</code></pre>
</div>
</div>
</section>
<section class="slide" id="property-file-snitch">
<h2>Property File Snitch</h2>
<div class="ulist">
<ul>
<li>Reads datacenter and rack information for all nodes from a file</li>
<li>You must keep files in sync with all nodes in the cluster</li>
<li>cassandra-topology.properties file</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>175.56.12.105=DC1:RAC1
175.50.13.200=DC1:RAC1
175.54.35.197=DC1:RAC2
175.54.35.152=DC1:RAC2

120.53.24.101=DC2:RAC1
120.55.16.200=DC2:RAC1
120.57.18.103=DC2:RAC2
120.57.18.177=DC2:RAC2</code></pre>
</div>
</div>
</section>
<section class="slide" id="gossiping-property-file-snitch">
<h2>Gossiping Property File Snitch</h2>
<div class="ulist">
<ul>
<li>Relieves the pain of the property file snitch</li>
<li>Declare the current node&#8217;s DC/rack information in a file</li>
<li>You must set each individual node&#8217;s settings</li>
<li>But you don&#8217;t have to copy settings as with property file snitch</li>
<li>Gossip spreads the setting through the cluster</li>
<li>cassandra-rackdc.properties file</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>dc=DC1
rack=RAC1</code></pre>
</div>
</div>
</section>
<section class="slide" id="rack-inferring-snitch">
<h2>Rack Inferring Snitch</h2>
<div class="ulist">
<ul>
<li>Infers the rack and DC from the IP address</li>
</ul>
</div>
<div class="paragraph"><p><span class="image"><img alt="rack-inferring" src="images/cassandra/internals/distributed-architecture/snitches/rack-inferring.svg" /></span></p></div>
</section>
<section class="slide" id="cloud-based-snitches">
<h2>Cloud-Based Snitches</h2>
<div class="paragraph"><p><strong>See documentation for details</strong></p></div>
<div class="ulist">
<ul>
<li><p>
Ec2Snitch<div class="ulist">
<ul>
<li>Single region Amazon EC2 deployment</li>
</ul>
</div></p></li>
<li><p>
Ec2MultiRegionSnitch<div class="ulist">
<ul>
<li>Multi-region Amazon EC2 deployment</li>
</ul>
</div></p></li>
<li><p>
GoogleCloudSnitch<div class="ulist">
<ul>
<li>Multi-region Google cloud deployment</li>
</ul>
</div></p></li>
<li><p>
Cloudstack Snitch<div class="ulist">
<ul>
<li>For Cloudstack environments</li>
</ul>
</div></p></li>
</ul>
</div>
</section>
<section class="slide" id="dynamic-snitch">
<h2>Dynamic Snitch</h2>
<div class="ulist">
<ul>
<li>Layered on top of your actual snitch</li>
<li>Maintains a pulse on each node&#8217;s performance</li>
<li>Determines which node to query replicas from depending on node health</li>
<li>Turned on by default for all snitches</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>For more information, see: <a class="bare" href="http://www.datastax.com/dev/blog/dynamic-snitching-in-cassandra-past-present-and-future">http://www.datastax.com/dev/blog/dynamic-snitching-in-cassandra-past-present-and-future</a></p></div>
</div>
</div>
</section>
<section class="slide" id="configuring-snitches">
<h2>Configuring Snitches</h2>
<div class="ulist">
<ul>
<li>All nodes in the cluster must use the same snitch</li>
<li>Changing cluster network topology requires restarting all nodes</li>
<li>Run sequential repair and cleanup on each node</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p><a class="bare" href="http://www.slideshare.net/planetcassandra/datastax-7-deadly-sins-for-cassandra-ops">http://www.slideshare.net/planetcassandra/datastax-7-deadly-sins-for-cassandra-ops</a></p></div>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-10">
<h2>Exercise 10&#8212;&#8203;Snitches</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-replication">
<h2>Replication</h2>

</section>
<section class="slide" id="replication">
<h2>Replication</h2>
<div class="paragraph" id="replr"><p><strong>Simple Strategy</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>One of Cassandra&#8217;s fault-tolerance strategies is replication. Replication is simply a matter of duplicating data across nodes. Cassandra performs this duplication on a partition basis. We set the replication factor on a per-table basis. Here we first examine SimpleStrategy replication.</p></div>
<div class="paragraph"><p>Animation 1: We will first look at a replication factor of one, meaning Cassandra will store only one copy of each partition in the cluster. This is a dangerous place to be, but it&#8217;s a good place to start the discussion.</p></div>
<div class="paragraph"><p>Animation 2: A write request to store data for partition 59 arrives.</p></div>
<div class="paragraph"><p>Animation 3: The upper right node will act as the coordinator.</p></div>
<div class="paragraph"><p>Animation 4: Notice 59 falls into the purple range. We change the partition color to purple to indicate this.</p></div>
<div class="paragraph"><p>Animation 5: The coordinator forwards the write request to the appropriate node.</p></div>
<div class="paragraph"><p>Animation 6: [Graphics clear.]</p></div>
<div class="paragraph"><p>Animation 7: Let&#8217;s increase the replication factor to two.</p></div>
<div class="paragraph"><p>Animation 8: This has the effect of doubling the range that each node is responsible for. For example, node 75 is not only responsible for tokens falling in the red range, but now node 75 will also store tokens falling in the purple range as well. Increasing the replication factor with SimpleStrategy has the effect of causing nodes to store replicas moving in a clockwise direction.</p></div>
<div class="paragraph"><p>Animation 9: Again our request to write partition with token 59 arrives.</p></div>
<div class="paragraph"><p>Animation 10: This time the coordinator forwards the write request to not only the purple node but also the red node as well.</p></div>
<div class="paragraph"><p>Animation 11: [Graphics fade.]</p></div>
<div class="paragraph"><p>Animation 12: Let&#8217;s increase the replication factor to three. Can you reason about how this changes our replication animation?</p></div>
<div class="paragraph"><p>Animation 13: Now the sky blue node, the red node, and the purple node are all responsible for the purple range. (It may help to consider each node and consider the colors leading into it from a counter-clockwise direction.)</p></div>
<div class="paragraph"><p>Animation 14: The write request comes in.</p></div>
<div class="paragraph"><p>Animation 15: The coordinator forwards the request to the appropriate replica nodes.</p></div>
<div class="paragraph"><p>Animation 16: [Graphics fade.]</p></div>
</div>
</div>
</section>
<section class="slide" id="node-failure">
<h2>Node Failure</h2>
<div class="paragraph"><p><span class="image"><img alt="shark-attack" src="images/cassandra/internals/distributed-architecture/replication/shark-attack.png" /></span></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Consider what happens when a node (or a few nodes) fail due to unforeseen circumstances.</p></div>
</div>
</div>
</section>
<section class="slide" id="request">
<h2>Request</h2>
<div class="paragraph" id="rqst"><p><strong>Simple Strategy</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Here we have two nodes that failed to survive the natural disaster. Notice these two also happen to be replica nodes for our partition 59 that we wrote to the cluster.</p></div>
<div class="paragraph"><p>Animation 1: A request for partition 59 arrives. Note any node can coordinate this request. We chose the bottom right node (which differs from the earlier write request coordinator node) for illustrative purposes.</p></div>
<div class="paragraph"><p>Animation 2: The coordinator can retrieve the replica from any of the three nodes. However, only one node is up.</p></div>
<div class="paragraph"><p>Animation 3: This node services the request, and the coordinator forwards the response back to the client. The client is blissfully unaware that a disaster has occurred.</p></div>
</div>
</div>
</section>
<section class="slide" id="multi-data-center-replication">
<h2>Multi Data Center Replication</h2>
<div class="paragraph" id="mdat"><p><strong>Network Topology Strategy</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Using SimpleStrategy is fine for training and tinkering purposes, however, in production, you most likely will have multiple data centers and want to distribute your replicas intelligently among them.</p></div>
<div class="paragraph"><p>Animation 1: We moved the nodes into separate data centers. Data centers are a logical concept to Cassandra, however, you will also want to physically position your nodes in correlation with your logical data centers. Notice we now have TWO rings instead of one. Although we maintained each node&#8217;s token value, both data centers make their own individual rings. It may help to cover one of the rings with your hand and look at them separately as individual rings.</p></div>
<div class="paragraph"><p>Animation 2: Here we show how to create a keyspace using NetworkTopologyStrategy. Notice the west data center will store two replicas, and the east data center will store three. How many replicas you store per data center is based on your organizational needs.</p></div>
<div class="paragraph"><p>Animation 3: A request comes to ANY node in the cluster. Again, this node acts as the coordinator. Before advancing the animation, try to determine which node in this data center must store replicas of this partition. Within the individual data center, it may help to think in terms of SimpleStrategy.</p></div>
<div class="paragraph"><p>Animation 4: Nodes 75 and 0 store the replicas as 59 falls into 75&#8217;s primary range, and 59 falls into 0&#8217;s secondary range. The coordinator also forwards the write request to the second data center. The node handling the write in the second data center acts as the <em>remote coordinator</em>. Can you determine which nodes will store the replicas before you advance the animation?</p></div>
<div class="paragraph"><p>Animation 5: Token 59 falls into the remote coordinator&#8217;s token range. With a replication factor of three in this data center, both nodes 88 and 13 store replicas as well.</p></div>
<div class="paragraph"><p>If one data center dies, no worries, the second data center can pick up the slack. Ideally you will also place your data centers geographically close to your clients as well to get around the speed of light problem.</p></div>
<div class="paragraph"><p>The major point to note here is that with simple strategy, replication simply walked around the ring. With network topology strategy, replication walks across data centers and replicates in each ring individually.</p></div>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-11">
<h2>Exercise 11&#8212;&#8203;Replication</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-consistency-level">
<h2>Consistency</h2>

</section>
<section class="slide" id="cap-theorem">
<h2>CAP Theorem</h2>
<div class="paragraph" id="dueji"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>CAP stands for consistency, availability, and partition tolerance. The CAP theorem applies only when you have a distributed system (like Cassandra) and there is a failure. When there is no failure, you get have all three.</p></div>
<div class="paragraph"><p>Consistency: The database replicas agree on the current state of the data.</p></div>
<div class="paragraph"><p>Availability: The cluster can return a response.</p></div>
<div class="paragraph"><p>Partition Tolerance: During a network partition (failure), Cassandra still serves requests.</p></div>
<div class="paragraph"><p><em>The CAP theorem only applies when there is a failure</em>. During a failure, a distributed database can only guarantee two of these. For example, during a network partition, we can be available and continue serving requests from both halves, but each half may not serve consistent data. If we decide we must be consistent and available, then we won&#8217;t put up with network partitions. If we want partition tolerance and consistency, then we simply won&#8217;t be available.</p></div>
<div class="paragraph"><p>Animation 1: Cassandra defaults to choosing partition tolerant and available. If there is a failure, by default, Cassandra feels it is better to serve some type of response, even if it is a stale response, rather than no response at all.</p></div>
<div class="paragraph"><p>However, Cassandra supports configuring your CAP choices at a <em>per query level</em>. Thus for one query, you can change Cassandra from being an AP database to an AC database for just a single query. We call this tunable consistency.</p></div>
<div class="paragraph"><p>In a big data scenario where there are multiple machines acting as your database, you have to make a choice here. There is no way around it. If you are serving users around the planet, unless you are willing to pay the time penalty for every request, there is no physical way to keep two geographically separated clusters in sync 100% of the time.</p></div>
</div>
</div>
</section>
<section class="slide" id="consistency-levels">
<h2>Consistency Levels</h2>
<div class="paragraph" id="cftw"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Here we have a simple cluster with a replication factor of one. Let&#8217;s explore what consistency levels mean in this scenario.</p></div>
<div class="paragraph"><p>Consistency comes into play with both writes and reads.</p></div>
<div class="paragraph"><p>Animation 1: A client makes a read or write request to the cluster. The top node acts as coordinator.</p></div>
<div class="paragraph"><p>Animation 2: The coordinator forwards the request to the appropriate replica nodes.</p></div>
<div class="paragraph"><p>Animation 3: We will first consider a consistency level of one.</p></div>
<div class="paragraph"><p>Animation 4: With consistency level one, only one replica node must acknowledge the write or return a result on a read.</p></div>
<div class="paragraph"><p>Animation 5: The coordinator returns the result to the client.</p></div>
<div class="paragraph"><p>Animation 6: Next we consider a consistency level of quorum.</p></div>
<div class="paragraph"><p>Animation 7: With quorum, a majority of the replica nodes must return a response. The coordinator selects the records with the latest timestamps and returns the result.</p></div>
<div class="paragraph"><p>Animation 8: Next we consider a consistency level of all.</p></div>
<div class="paragraph"><p>Animation 9: This is much like quorum except ALL replica nodes must provide a result for the coordinator to consider.</p></div>
</div>
</div>
</section>
<section class="slide" id="strong-consistency">
<h2>Strong Consistency</h2>
<div class="paragraph" id="hicu"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>If you require strong consistency (that is, you always have the latest result), there are a few ways to accomplish that. However, you will pay for it in latency.</p></div>
<div class="paragraph"><p>Animation 1: Client makes a WRITE request. Left node acts as coordinator.</p></div>
<div class="paragraph"><p>Animation 2: Coordinator forwards the write request to replica nodes.</p></div>
<div class="paragraph"><p>Animation 3: Consistency level ALL requires that all three replica nodes acknowledge the write.</p></div>
<div class="paragraph"><p>Animation 4: Since you know that all three nodes acknowledged the previous write, you only need to read at consistency level ONE to get the latest result. Any of the three replica nodes will return the latest data.</p></div>
<div class="paragraph"><p>Animation 5: The cluster returns a response back to the client.</p></div>
</div>
</div>
</section>
<section class="slide" id="consistency-level-quorum">
<h2>Consistency Level Quorum</h2>
<div class="paragraph" id="strq"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Let&#8217;s consider what you must do to get a strong (latest result) response back when using consistency level QUORUM.</p></div>
<div class="paragraph"><p>Animation 1: Client writes at QUORUM.</p></div>
<div class="paragraph"><p>Animation 2: The client must also read at quorum. Notice the data read from the bottom node which is not yet consistent with the data on the top and right node. However, the read also read from the right node which is consistent. The coordinator will drop the stale data from the bottom node and return the latest data from the right node.</p></div>
</div>
</div>
</section>
<section class="slide" id="consistency-level-one">
<h2>Consistency Level One</h2>
<div class="paragraph" id="cloney"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Now we will consider the situation with a consistency level of ONE.</p></div>
<div class="paragraph"><p>Animation 1: Client writes at consistency level of one. The top node acknowledges the write. The right and bottom nodes will eventually acknowledge the writes, but for this instant in time, they still have stale data.</p></div>
<div class="paragraph"><p>Animation 2: Client reads at consistency level one. The bottom node returns a result faster than the other two, however, that result is stale.</p></div>
<div class="paragraph"><p>When writing at one and reading at one, we cannot guarantee consistent (latest, not stale) data. In order to guarantee consistent results, our write consistency level plus our read consistency level must be greater than our replication factor.</p></div>
<div class="paragraph"><p>Again, you will pay for this with latency.</p></div>
<div class="paragraph"><p>But you may be surprised. Writing and reading at consistency level one is the least latent way to go, and there is a chance you may not get consistent results. But Netflix did a stress test with this scenario and found that they could always rely on writing and reading at one: <a class="bare" href="https://youtu.be/A6qzx_HE3EU?t=4m7s">https://youtu.be/A6qzx_HE3EU?t=4m7s</a></p></div>
</div>
</div>
</section>
<section class="slide" id="consistency-across-data-centers">
<h2>Consistency Across Data Centers</h2>
<div class="ulist" id="qvlq">
<ul>
<li>QUORUM vs. LOCAL_QUORUM</li>
<li>Cross DC consistency is a performance hit!</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Now we will examine how consistency levels affect performance in a multi-data center scenario. Here we have two data centers.</p></div>
<div class="paragraph"><p>Animation 1: Client makes a write or read request to the cluster.</p></div>
<div class="paragraph"><p>Animation 2: If the consistency level is LOCAL_QUORUM, then only the target data center must achieve quorum consistency before acknowledging the write or returning a result set on a read.</p></div>
<div class="paragraph"><p>Animation 3: As we have seen before, however, the coordinator will forward the request to the second data center via a remote coordinator.</p></div>
<div class="paragraph"><p>Animation 4: If your request is consistency level QUORUM vs. LOCAL_QUORUM, then to have a majority vote, both coordinators must concur on the result since two in this case would make the majority.</p></div>
<div class="paragraph"><p>Again, the cost here is time.</p></div>
</div>
</div>
</section>
<section class="slide" id="consistency-settings">
<h2>Consistency Settings</h2>
<div class="paragraph"><p><strong>In order of weakest to strongest</strong></p></div>
<table class="tableblock frame-all grid-all" style="width:100%">
<colgroup>
<col style="width:50%" />
<col style="width:50%" />
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Setting</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ANY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Storing a hint at minimum is satisfactory</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ALL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Every node must participate</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ONE, TWO, THREE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Checks closest node(s) to coordinator</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">QUORUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Majority vote, (sum_of_replication_factors / 2) + 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOCAL_ONE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Closest node to coordinator in same data center</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LOCAL_QUORUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Closest quorum of nodes in same data center</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">EACH_QUORUM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Quorum of nodes in each data center, applies to writes only</p></td>
</tr>
</tbody>
</table>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Search for the term closest in the page at <a class="bare" href="https://wiki.apache.org/cassandra/ArchitectureInternals">https://wiki.apache.org/cassandra/ArchitectureInternals</a> for more information.</p></div>
</div>
</div>
</section>
<section class="slide" id="consistency-settings-2">
<h2>Consistency Settings</h2>
<div class="ulist">
<ul>
<li><p>
The higher the consistency, the less chance you may get stale data<div class="ulist">
<ul>
<li>Pay for this with latency</li>
<li>Depends on your situational needs</li>
</ul>
</div></p></li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-12">
<h2>Exercise 12&#8212;&#8203;Consistency Level</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-hinted-handoff">
<h2>Hinted Handoff</h2>

</section>
<section class="slide" id="failed-writes">
<h2>Failed Writes</h2>
<div class="paragraph" id="hhdoff"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Depending on your consistency level, you can still service write requests even when nodes are down. Cassandra accomplishes this via hinted handoff.</p></div>
<div class="paragraph"><p>Animation 1: A write request comes into the cluster. Replication factor is three.</p></div>
<div class="paragraph"><p>Animation 2: As usual, the coordinator forwards the write requests to the replica nodes.</p></div>
<div class="paragraph"><p>Animation 3: [Replica 2 forward]</p></div>
<div class="paragraph"><p>Animation 4: The coordinator forwards the request to the third replica node. However, this node is down.</p></div>
<div class="paragraph"><p>Animation 5: Although the coordinator is NOT a replica node, it stores the replica to send to the down node after that node comes online again.</p></div>
<div class="paragraph"><p>Animation 6: Cassandra acknowledges the write back to the client as successful.</p></div>
<div class="paragraph"><p>Animation 7: Our node comes back online.</p></div>
<div class="paragraph"><p>Animation 8: Once aware, the former coordinator node forwards the write to the now online replica node.</p></div>
</div>
</div>
</section>
<section class="slide" id="consistency-level">
<h2>Consistency Level</h2>
<div class="ulist">
<ul>
<li>Consistency level of ANY means storing a hint suffices</li>
<li>Consistency level of ONE or more means at least one replica must successfully write</li>
<li>Hint does not suffice</li>
</ul>
</div>
</section>
<section class="slide" id="settings">
<h2>Settings</h2>
<div class="ulist">
<ul>
<li>cassandra.yaml</li>
<li>You can disable hinted handoff</li>
<li>Set the amount of time a node will store a hint</li>
<li>Default is three hours</li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-13">
<h2>Exercise 13&#8212;&#8203;Hinted Handoff</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-distributed-architecture-read-repair">
<h2>Read Repair</h2>

</section>
<section class="slide" id="anti-entropy-operations">
<h2>Anti-Entropy Operations</h2>
<div class="ulist">
<ul>
<li>Network partitions cause nodes to get out of sync</li>
<li>You must choose between availability vs. consistency level</li>
<li>CAP Theorem</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Due to network troubles, nodes failing, corrupted disks, etc. over time nodes can get out of sync with each other concerning replicas.</p></div>
<div class="paragraph"><p>When querying your Cassandra database, you have to decide between consistency vs. availability <em>during a network partition</em>. This goes back to the CAP theorem. With Cassandra, you can tune whether nodes are always in sync with each other vs. being highly available. When there is a network partition, do you want to force clients to wait until the system is in a consistent state, or do you want to give the clients the best possible answer available?</p></div>
<div class="paragraph"><p>Choosing availability means there could be a disagreement between replicas as to the actual data value during a partition.</p></div>
</div>
</div>
</section>
<section class="slide" id="normal-read">
<h2>Normal Read</h2>
<div class="paragraph" id="nrred"><p><strong>Satisfying Consistency Level</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Let&#8217;s examine in detail what generally happens on a read with a full consistency level. Here is our cluster with data.</p></div>
<div class="paragraph"><p>Animation 1: A request comes into the cluster. Left node acts as the coordinator.</p></div>
<div class="paragraph"><p>Animation 2: This request has a consistency level of ALL, the highest consistency level you can require. These three nodes store the replicas of interest.</p></div>
<div class="paragraph"><p>Animation 3: The coordinator forwards the request to the most responsive node which is the node on the bottom.</p></div>
<div class="paragraph"><p>Animation 4: The coordinator also forwards the request to the other replica nodes, but the coordinator only requires a digest (a checksum) of the data, not the actual data. This is an optimization.</p></div>
<div class="paragraph"><p>Animation 5: This first node retrieves the replica.</p></div>
<div class="paragraph"><p>Animation 6: The other nodes perform the checksum.</p></div>
<div class="paragraph"><p>Animation 7: The first node returns the replica.</p></div>
<div class="paragraph"><p>Animation 8: The other two return their checksums.</p></div>
<div class="paragraph"><p>Animation 9: The coordinator executes the checksum on the data returned by the bottom node.</p></div>
<div class="paragraph"><p>Animation 10: The coordinator compares all of the checksums and determines that they match.</p></div>
<div class="paragraph"><p>Animation 12: The coordinator returns the data to the client.</p></div>
</div>
</div>
</section>
<section class="slide" id="read-repair">
<h2>Read Repair</h2>
<div class="paragraph" id="rdrpairr"><p><strong>Keeping data in sync</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Now let&#8217;s consider a similar scenario where the checksums don&#8217;t match, however.</p></div>
<div class="paragraph"><p>Animation 1: Again, a request comes into the cluster; left node acts as coordinator.</p></div>
<div class="paragraph"><p>Animation 2: Consistency level is ALL, meaning, the coordinator must verify ALL replicas are in sync.</p></div>
<div class="paragraph"><p>Animation 3: Coordinator forwards the request to the most responsive node.</p></div>
<div class="paragraph"><p>Animation 4: Coordinator requests checksums from the other two nodes.</p></div>
<div class="paragraph"><p>Animation 5: Bottom node retrieves the replica.</p></div>
<div class="paragraph"><p>Animation 6: Other nodes compute the checksums. Notice the checksum values do not match in this case.</p></div>
<div class="paragraph"><p>Animation 7: Bottom node returns the replica.</p></div>
<div class="paragraph"><p>Animation 8: Other two return their checksums.</p></div>
<div class="paragraph"><p>Animation 9: Coordinator performs checksum on the replica that the bottom node returned.</p></div>
<div class="paragraph"><p>Animation 10: Coordinator compares the checksums and finds they do not match. The coordinator is responsible for syncing all the nodes with the latest data.</p></div>
<div class="paragraph"><p>Animation 11: [Checksums fade out.]</p></div>
<div class="paragraph"><p>Animation 12: Recall that each cell of data stores a timestamp. The coordinator can use this timestamp to determine which replica has the latest data. In this case, the replica returned by the bottom node has a timestamp of 135.</p></div>
<div class="paragraph"><p>Animation 13: The coordinator requests the full replicas from the other two nodes.</p></div>
<div class="paragraph"><p>Animation 14: The two replica nodes retrieve their copies.</p></div>
<div class="paragraph"><p>Animation 15: The two nodes return their replicas. Notice the right node has the latest timestamp of 159.</p></div>
<div class="paragraph"><p>Animation 16: The coordinator discards the older replicas.</p></div>
<div class="paragraph"><p>Animation 17: The coordinator sends copies of the latest replica to the nodes that are out of date.</p></div>
<div class="paragraph"><p>Animation 18: The coordinator returns the requested (latest) data.</p></div>
</div>
</div>
</section>
<section class="slide" id="read-repair-chance">
<h2>Read Repair Chance</h2>
<div class="ulist">
<ul>
<li>Performed when read is at a consistency level less than ALL</li>
<li>Request reads only a subset of the replicas</li>
<li>We can&#8217;t be sure replicas are in sync</li>
<li>Generally you are safe, but no guarantees</li>
<li>Response sent immediately when consistency level is met</li>
<li>Read repair done asynchronously in the background</li>
<li>10% by default</li>
</ul>
</div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Obviously executing queries with a consistency level of ALL trades time for having correct results 100% of the time. Depending on your situation, you may find you require less consistency where only most of the time you will get the correct result.</p></div>
<div class="paragraph"><p>In cases where you query for a consistency level less than ALL, Cassandra will still perform a read repair probabilistically. This probability is configurable, but it defaults to 10% of the time. However, when Cassandra performs a read repair under these circumstances, it does so asynchronously. That is, the client may receive stale data, but Cassandra synchronizes the data immediately after for any further requests on that particular result set.</p></div>
</div>
</div>
</section>
<section class="slide" id="nodetool-repair">
<h2>Nodetool Repair</h2>
<div class="ulist">
<ul>
<li>Syncs all data in the cluster</li>
<li><p>
Expensive<div class="ulist">
<ul>
<li>Grows with amount of data in cluster</li>
</ul>
</div></p></li>
<li>Use with clusters servicing high writes/deletes</li>
<li>Last line of defense</li>
<li>Run to synchronize a failed node coming back online</li>
<li>Run on nodes not read from very often</li>
</ul>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-14">
<h2>Exercise 14&#8212;&#8203;Read Repair</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-node-architecture-storage-engine-write-path">
<h2>Write Path</h2>

</section>
<section class="slide" id="write">
<h2>Write</h2>
<div class="paragraph" id="happyserver"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Now we will learn about Cassandra&#8217;s write path, which is how Cassandra converts a request to a saved state on a single node.</p></div>
<div class="paragraph"><p>Here is a single (happy) Cassandra node.</p></div>
<div class="paragraph"><p>Animation 1: A write request comes to this node via a client or coordinator node.</p></div>
</div>
</div>
</section>
<section class="slide" id="write-path">
<h2>Write Path</h2>
<div class="paragraph" id="writepth"><p><strong>Inside a Cassandra node&#8230;&#8203;</strong></p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Now we examine what happens internally inside of this node to handle this request.</p></div>
<div class="paragraph"><p>Notice the top rectangle represents the hard drive. The bottom portion represents memory.</p></div>
<div class="paragraph"><p>Animation 1: The write request arrives.</p></div>
<div class="paragraph"><p>Animation 2: Cassandra stores the write both in a in-memory structure called a MemTable and in another structure called the commit log on the hard disk. The commit log is the first place where the write is durable. Cassandra writes to the commit log serially instead of seeking throughout the commit log to update a record in place. The commit log is essentially a record of all updates (INSERT, UDPATE, DELETE) and can be replayed if the node crashes.</p></div>
<div class="paragraph"><p>Animation 3: An acknowledgement is sent back to the client/coordiantor. Notice how fast the write was. We store the record in memory for fast reading later and simply record the action on disk in the commit log.</p></div>
<div class="paragraph"><p>Animation 4: [Ack text fades]</p></div>
<div class="paragraph"><p>Animation 5: A second insert request arrives.</p></div>
<div class="paragraph"><p>Animation 6: Again, we append a copy to the end of the commit log.</p></div>
<div class="paragraph"><p>Animation 7: However, Cassandra stores the record sorted by clustering columns in memory. In this example we partition by state and cluster by city. So Cassandra inserts this record of Dallas before the previous record of Houston.</p></div>
<div class="paragraph"><p>Animation 8: Another write request arrives. What will happen next?</p></div>
<div class="paragraph"><p>Animation 9: Again we append to the commit log and insert the record of Snyder at the end of our MemTable.</p></div>
<div class="paragraph"><p>Animation 10: Record with city of Austin arrives.</p></div>
<div class="paragraph"><p>Animation 11: Again we append to the commit log and insert in order in the MemTable.</p></div>
<div class="paragraph"><p>Animation 12: Another Dallas record arrives.</p></div>
<div class="paragraph"><p>Animation 13: Again append and insert.</p></div>
<div class="paragraph"><p>Animation 14: Lastly El Paso arrives.</p></div>
<div class="paragraph"><p>Animation 15: Append and insert.</p></div>
<div class="paragraph"><p>Animation 16: Depending on your settings, eventually the MemTable becomes too large to store, so Cassandra flushes it as is to disk.</p></div>
<div class="paragraph"><p>Animation 17: Now that our MemTable is now durable on disk, the commit log for this data is no longer necessary, and Cassandra marks it for deletion.</p></div>
<div class="paragraph"><p>Animation 18: [Commit log fades.]</p></div>
<div class="paragraph"><p>Animation 19: We call this on-disk version of the MemTable an SSTable, which stands for sorted string table because Cassandra stores the table sorted by partition tokens and clustering columns.</p></div>
<div class="paragraph"><p>Animation 20: SSTables are immutable. Once written, Cassandra will not update, insert, or delete their values. We will see later how Cassandra handles reading the latest results.</p></div>
<div class="paragraph"><p>Animation 21: Since the commit log is a serially written data structure, if you&#8217;re not using SSDs, we strongly recommend placing it on its own drive as to not have the hard drive head compete with SSTable flushes or read requests.</p></div>
<div class="paragraph"><p>Animation 22: Now that you understand the commit log, we visually drop it from the next animation for illustrative purposes, but remember that every INSERT/UPDATE/DELETE also causes a write to the commit log.</p></div>
<div class="paragraph"><p>Animation 23: We expand hard drive 2&#8217;s screen real estate here for the next illustration.</p></div>
<div class="paragraph"><p>Animation 24: And also slide the MemTable over. :)</p></div>
<div class="paragraph"><p>Animation 25: Again several write requests come to the node. The node stores the records in memory ordered by their clustering column values.</p></div>
<div class="paragraph"><p>Animation 26: The MemTable fills, and Cassandra again flushes this MemTable to disk creating a second SSTable.</p></div>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-15">
<h2>Exercise 15&#8212;&#8203;Write Path</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-node-architecture-storage-engine-read-path">
<h2>Read Path</h2>

</section>
<section class="slide" id="reading-data">
<h2>Reading Data</h2>
<div class="paragraph" id="memss"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Now we examine the process Cassandra goes through to service a read request.</p></div>
<div class="paragraph"><p>Animation 1: Recall that during operation, a Cassandra node maintains one MemTable and stores several SSTables built up over time.</p></div>
<div class="paragraph"><p>Animation 2: To perform a read, Cassandra examines the contents of the MemTable&#8230;&#8203;</p></div>
<div class="paragraph"><p>Animation 3: and SSTables.</p></div>
<div class="paragraph"><p>Animation 4: [Both diagrams fade back in.]</p></div>
</div>
</div>
</section>
<section class="slide" id="reading-a-memtable">
<h2>Reading a MemTable</h2>
<div class="paragraph" id="memreading"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Reading from a MemTable is straightforward.</p></div>
<div class="paragraph"><p>Animation 1: A request for the partition of token 58 arrives.</p></div>
<div class="paragraph"><p>Animation 2: Cassandra easily locates the in-memory portion of the partition and returns the result.</p></div>
</div>
</div>
</section>
<section class="slide" id="reading-an-sstable">
<h2>Reading an SSTable</h2>
<div class="paragraph" id="ssreading"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Reading an SSTable is a bit more involved.</p></div>
<div class="paragraph"><p>Animation 1: Here are our sorted partitions on disk.</p></div>
<div class="paragraph"><p>Animation 2: Here are the byte offsets into this one SSTable file. The byte offsets indicate where in the file the beginning of each partition resides.</p></div>
<div class="paragraph"><p>Animation 3: Cassandra stores these byte offsets in an on-disk data structure called a <em>partition index</em>. Notice the partition index associates each partition token with its accompanying byte offset.</p></div>
<div class="paragraph"><p>Animation 4: When a request for partition with a token of 58 arrives, Cassandra searches the <em>partition index</em> and finds that that partition begins at byte offset 7,192.</p></div>
<div class="paragraph"><p>Animation 5: Cassandra then seeks directly into the SSTable file and reads the partition from disk.</p></div>
<div class="paragraph"><p>Animation 6: Cassandra returns the partition.</p></div>
<div class="paragraph"><p>Animation 7: However, these SSTables can become rather large and store several partitions. Thus the size of the partition index can become quite cumbersome to linearly search through to find the proper partition.</p></div>
<div class="paragraph"><p>Animation 8: [Graphic fades.]</p></div>
<div class="paragraph"><p>Animation 9: Recall that the partition index is an on disk structure. Here we show the byte offsets for some arbitrary but somewhat consistently spaced partition index entries.</p></div>
<div class="paragraph"><p>Animation 10: To speed up partition index lookups, Cassandra maintains a second data structure in memory called the partition summary. This acts as an index into the partition index. Notice the left column stores token ranges, whereas the right column stores the byte offsets into the partition index. Thus Cassandra should start its search for tokens from 0 to 20 within the partition index at byte offset 0. For all tokens from 21 to 55, Cassandra should start its search at byte offset 32. And for all tokens from 56 to 100, Cassandra should start its search at byte offset 48. Thus, Cassandra must still perform a linear search within the partition index, but the partition summary gives Cassandra a more optimal location to begin that search.</p></div>
<div class="paragraph"><p>Animation 11: Here we query for partition with token 36. 36 falls in the range of 21 to 55. The partition summary indicates Cassandra must start its search for that token at byte offset 32 within the partition index.</p></div>
<div class="paragraph"><p>Animation 12: Cassandra begins its search at byte offset 32 in the partition index. Cassandra first finds partition token 21, which is not the token Cassandra is looking for (36).</p></div>
<div class="paragraph"><p>Animation 13: Cassandra moves to the next entry in the partition index. This entry is token 36, Cassandra sees that this partition starts at byte offset 6,224 within the SSTable.</p></div>
<div class="paragraph"><p>Animation 14: Cassandra then seeks directly to the location where the partition resides.</p></div>
<div class="paragraph"><p>Animation 15: Cassandra returns the result back to the client/coordinator. To avoid this lookup process for future reads, Cassandra introduces yet another in-memory data structured called the key cache.</p></div>
<div class="paragraph"><p>Animation 16: Cassandra stores the token value and SSTable byte offset into the key cache.</p></div>
<div class="paragraph"><p>Animation 17: The next time a request for partition with a token of 36 arrives&#8230;&#8203;</p></div>
<div class="paragraph"><p>Animation 18: Cassandra circumvents the entire partition summary and partition index process to jump directly to where the partition resides within the file.</p></div>
<div class="paragraph"><p>Animation 19: Cassandra returns the result.</p></div>
<div class="paragraph"><p>Animation 20: But that is not all! Cassandra also has yet another optimization called the <em>bloom filter</em>, which this purple box represents. Bloom filters inform Cassandra as to whether or not the desired partition exists. If a bloom filter states that the partition does not exist, then it does not exist. However, a bloom filter may be unsure and say the value may exist when it actually doesn&#8217;t. This is called a false positive. Bloom filters cannot determine if the value exists for certain. They state that the value could possibly be there or, for a fact, the value is not there. Bloom filters act independent of the key cache, partition summary, and partition index.</p></div>
<div class="paragraph"><p>Animation 21: A request for partition with token 36 arrives. We can see clearly that that partition exists in this SSTable. However, the bloom filter states that the record MAY exist in the partition, so the request continues onto the key cache+partition summary+partition index process.</p></div>
<div class="paragraph"><p>Animation 22: [Graphics clear.]</p></div>
<div class="paragraph"><p>Animation 23: Here&#8217;s a request for the partition with token value 48. Notice this partition does not exist in our SSTable.</p></div>
<div class="paragraph"><p>Animation 24: In this scenario the bloom filter determines the same as we can with our eyes and stops the lookup right there.</p></div>
<div class="paragraph"><p>Animation 25: [Graphics clear.]</p></div>
<div class="paragraph"><p>Animation 26: Here&#8217;s a request for partition with token 74. Notice this partition does not exist in our SSTable.</p></div>
<div class="paragraph"><p>Animation 27: However, the bloom filter is unsure as to whether partition 74 exists or doesn&#8217;t.</p></div>
<div class="paragraph"><p>Animation 28: So the search continues through to the partition key/partition summary process where Cassandra will eventually discover that the partition does not exist.</p></div>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-16">
<h2>Exercise 16&#8212;&#8203;Read Path</h2>

</section>
<section class="slide transition-green" id="cassandra-internals-node-architecture-storage-engine-compaction">
<h2>Compaction</h2>

</section>
<section class="slide" id="reading-sstables">
<h2>Reading SSTables</h2>
<div class="paragraph" id="multss"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>As illustrated in the read-path module, reading from an SSTable is a laborious process.</p></div>
<div class="paragraph"><p>Animation 1: As the write-path module illustrates, the number of SSTables build up over time due to INSERT/UPDATE/DELETEs. Cassandra goes through this procedure for every SSTable on disk.</p></div>
</div>
</div>
</section>
<section class="slide" id="compacting-partitions">
<h2>Compacting Partitions</h2>
<div class="paragraph" id="cmppart"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>In order to reduce the number of SSTables on disk, Cassandra routinely performs a maintenance operation called <em>compaction</em>.</p></div>
<div class="paragraph"><p>Here are two partitions of users in Texas, each partition is from a different SSTable. We will first examine the process of compacting two partitions together from two seperate SSTables. Then we will examine compacting SSTables themselves with several partitions.</p></div>
<div class="paragraph"><p>The first column to the left of these partitions are the row IDs. Typically these would be a UUID, but for illustrative purposes we simplified them to basic integers.</p></div>
<div class="paragraph"><p>Notice the numbers in parenthesis next to each value. The numbers represent the timestamp of when that value was written. The timestamps of the values on the left are less than the timestamps of the values on the right. This is because the SSTable the left partition is in was written to disk first. The (X)s represent tombstones which indicate a deletion.</p></div>
<div class="paragraph"><p>Animation 1: We will compact these two partitions together into a single partition.</p></div>
<div class="paragraph"><p>Animation 2: We first consider the first row with the name Johnny. It appears Johnny either INSERTed or UPDATEd his name to be the same value later. Notice the record on the right is newer than the one on the left.</p></div>
<div class="paragraph"><p>Animation 3: Thus Cassandra discards the record on the left and writes the one on the write into the new SSTable.</p></div>
<div class="paragraph"><p>Animation 4: Next we consider Betsy&#8217;s record.</p></div>
<div class="paragraph"><p>Animation 5: It appears she became a user and then quit, so a delete was written into the SSTable on the right as the latest update to her record.</p></div>
<div class="paragraph"><p>Animation 6: Cassandra drops both records from each table, essentially performing the actual delete.</p></div>
<div class="paragraph"><p>Animation 7: Next is Nicholi, or is it Norman? Either way, it&#8217;s record 3. Nicholi must have changed their name to Norman later since that version has the largest timestamp.</p></div>
<div class="paragraph"><p>Animation 8: Cassandra writes Norman to the new SSTable.</p></div>
<div class="paragraph"><p>Animation 9: Here is Sue with an ID of 4. Sue doesn&#8217;t change her mind like our previous users did, so she writes her name once. This write sits by itself in the left SSTable.</p></div>
<div class="paragraph"><p>Animation 10: Since it is the latest (and only) record for Sue, Cassandra writes this value to the new SSTable.</p></div>
<div class="paragraph"><p>Animation 11: Here&#8217;s Sam with an ID of 5. Looks like he signed up and then quit later.</p></div>
<div class="paragraph"><p>Animation 12: However, he just recently quit, and his tombstone has not yet passed gc_grace_seconds, so Cassandra writes this tombstone to the new SSTable.</p></div>
<div class="paragraph"><p>Animation 13: Last but not least is Henrie, who just barely joined killrVideo.</p></div>
<div class="paragraph"><p>Animation 14: Cassandra writes Henrie&#8217;s record to the new SSTable and then deletes the two source SSTables.</p></div>
</div>
</div>
</section>
<section class="slide" id="compacting-sstables">
<h2>Compacting SSTables</h2>
<div class="paragraph" id="cmpss"><p>&#160;</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Here are two SSTables with partitions, each partition marked by its token.</p></div>
<div class="paragraph"><p>Animation 1: We will compact these two SSTables into a single SSTable.</p></div>
<div class="paragraph"><p>Animation 2: Notice partition 3 only resides in the bottom SSTable, so Cassandra copies partition 3 directly to the new SSTable. Notice that this partition did not change size in the new SSTable. More on this later.</p></div>
<div class="paragraph"><p>Animation 3: Partition 7 resides in both SSTables.</p></div>
<div class="paragraph"><p>Animation 4: When compacting partition 7 into the new SSTable, Cassandra found several updates to the records. As we saw in the previous slide, Cassandra only retains the latest update on compaction, so several prior INSERTS/UPDATES/DELETEs are dropped from partition 7, and it becomes smaller than either of the source partitions.</p></div>
<div class="paragraph"><p>Animation 5: Like partition 3, partition 13 comes from only one source SSTable.</p></div>
<div class="paragraph"><p>Animation 6: However, unlike partition 3, partition 13 has several tombstones past their gc_grace_seconds in it. Thus Cassandra removes these tombstones when writing partition 13 to the new SSTable.</p></div>
<div class="paragraph"><p>Animation 7: Both SSTables contain portions of partition 18.</p></div>
<div class="paragraph"><p>Animation 8: Since there are several INSERT/UPDATE/DELETES in both copies, Cassandra drops most of them only writing the latest data combined with any tombstones not past gc_grace_seconds.</p></div>
<div class="paragraph"><p>Animation 9: Partition 21 has all unique values in it, no tombstones past gc_grace_seconds (or perhaps no tombstones at all), so similar to partition 3, Cassandra writes partition 21 directly to the new SSTable as is.</p></div>
<div class="paragraph"><p>Animation 10: Same story with partition 36, but notice it comes from the second SSTable instead of the first.</p></div>
<div class="paragraph"><p>Animation 11: However 36 has some tombstones to drop.</p></div>
<div class="paragraph"><p>Animation 12: Partitions 58 will combine&#8230;&#8203;</p></div>
<div class="paragraph"><p>Animation 13: into a larger partition because both contain unique records.</p></div>
<div class="paragraph"><p>Animation 14: Partition 84 only has tombstones that are past their gc_grace_seconds.</p></div>
<div class="paragraph"><p>Animation 15: So Cassandra drops that partition completely.</p></div>
<div class="paragraph"><p>Animation 16: Same story with partition 92, so Cassandra drops it as well. Cassandra no longer needs the previous two SSTables, so Cassandra deletes the SSTables from disk. Now we have a single, smaller, compacted SSTable. It takes less room on our hard drive, plus it&#8217;s one less SSTable Cassandra must consider when fulfilling a read request.</p></div>
</div>
</div>
</section>
<section class="slide" id="compacting-strategies">
<h2>Compacting Strategies</h2>
<div class="paragraph"><p>Compaction strategies are configurable. These strategies include:</p></div>
<div class="ulist">
<ul>
<li>SizeTiered Compaction - (Default) triggers when multiple SSTables of a similar size are present.</li>
<li>Leveled Compaction - groups SSTables into levels, each of which has a fixed size limit which is 10 times larger than the previous level.</li>
<li>DateTiered Compaction  - stores data written within a the same time period in the same SSTable.</li>
</ul>
</div>
<div class="paragraph"><p>Use the <code><code>ALTER TABLE</code></code> command to change the strategy.</p></div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay"><code>ALTER TABLE mykeyspace.mytable WITH compaction = { 'class' :  'LeveledCompactionStrategy'  };</code></pre>
</div>
</div>
</section>
<section class="slide transition-purple" id="courses-DS201-transitions-exercises-exercise-17">
<h2>Exercise 17&#8212;&#8203;Compaction</h2>

</section>
<section class="slide transition-green" id="cassandra-dev-theory-big-data">
<h2>Big Data</h2>

</section>
<section class="slide" id="big-data">
<h2>Big Data</h2>
<div class="paragraph"><p><strong>It&#8217;s more than just size&#8230;&#8203;</strong></p></div>
<div class="ulist">
<ul>
<li>Velocity</li>
<li>Volume</li>
<li>Variety</li>
</ul>
</div>
<div class="paragraph"><p>The three Vs</p></div>
<div class="openblock notes">
<div class="content">
<div class="paragraph"><p>Big data isn&#8217;t just about volume of data. Having only a large volume of data means you have a storage problem.</p></div>
<div class="paragraph"><p>Big data applications ingest and deliver data at high rates of speed. Usually such applications are driven by thousands of users interacting with the system at a high rate, but sensors and internet of things (IOT) networks can also produce data at extreme rates.</p></div>
<div class="paragraph"><p>Big data applications require high availability (low to zero downtime). They also require response times to be consistently low. Cassandra excels in these areas!</p></div>
</div>
</div>
</section>
<section class="slide" id="big-data-vs-relational-databases">
<h2>Big Data vs Relational Databases</h2>
<div class="paragraph"><p><strong>The dinosaur architecture just doesn&#8217;t cut it anymore</strong></p></div>
<div class="paragraph"><p><span class="image" style="float: right"><img alt="old-dinosaur" src="images/cassandra/dev/theory/big-data/old-dinosaur.jpg" /></span></p></div>
<div class="ulist">
<ul>
<li><p>
Modern applications have different priorities<div class="ulist">
<ul>
<li>Need for speed trumps consistency</li>
<li>Commodity server racks trump massive high-end systems</li>
</ul>
</div></p></li>
<li>Large table joins are too time consuming</li>
<li>Sharding is hell</li>
</ul>
</div>
</section>
<section class="slide" id="acid">
<h2>ACID</h2>
<div class="ulist">
<ul>
<li>Atomicity</li>
<li>Consistency</li>
<li>Isolation</li>
<li>Durability</li>
</ul>
</div>
<div class="paragraph"><p>Do you really need all of these in your application 100% of the time?</p></div>
<div class="ulist">
<ul>
<li>If so, you must pay for it, usually in latency.</li>
<li>In Cassandra, you trade off some of these for performance.</li>
</ul>
</div>
</section>
<section class="slide" id="cassandra-data-model">
<h2>Cassandra Data Model</h2>
<div class="paragraph"><p><strong>Queries are king!</strong></p></div>
<div class="paragraph"><p><span class="image" style="float: right"><img alt="king-query" height="500" src="images/cassandra/dev/theory/big-data/king-query.svg" /></span></p></div>
<div class="ulist">
<ul>
<li>Relational stores data in a domain-friendly format</li>
<li>Cassandra stores data in query-friendly format</li>
<li>Take our DS220 Data Modeling course to learn how</li>
</ul>
</div>
</section>
<section class="slide transition-green" id="courses-DS201-custom-content-conclusion">
<h2>Conclusion</h2>

</section>
<section class="slide" id="more-courses">
<h2>More Courses!</h2>
<div class="paragraph"><p><strong>Available on DataStax Academy</strong></p></div>
<div class="ulist">
<ul>
<li>DS101 Introduction to Apache Cassandra</li>
<li>DS210 Operations and Performance Tuning</li>
<li>DS220 Data Modeling with Apache Cassandra</li>
<li>DS310 DataStax Enterprise Search with Apache Solr</li>
<li>DS320 DataStax Enterprise Analytics with Apache Spark</li>
</ul>
</div>
</section>
<section class="slide" id="ds101-introduction-to-apache-cassandra">
<h2>DS101 Introduction to Apache Cassandra</h2>
<div class="ulist">
<ul>
<li>High level overview of concepts covered in this course</li>
<li>Recorded by two of DataStax&#8217;s most handsome employees</li>
</ul>
</div>
</section>
<section class="slide" id="ds210-operations-and-performance-tuning">
<h2>DS210 Operations and Performance Tuning</h2>
<div class="ulist">
<ul>
<li>Cassandra management</li>
<li>Best practices</li>
<li>Adding/removing nodes</li>
<li>Repair</li>
<li>Security</li>
<li>Multiple data centers</li>
<li>Hardware planning/tuning</li>
</ul>
</div>
</section>
<section class="slide" id="ds220-data-modeling-with-apache-cassandra">
<h2>DS220 Data Modeling with Apache Cassandra</h2>
<div class="ulist">
<ul>
<li>Uses ER and Chebotko diagrams to create an optimal Cassandra data model</li>
<li><p>
Covers the three core levels of data modeling<div class="ulist">
<ul>
<li>Conceptual</li>
<li>Logical</li>
<li>Physical</li>
</ul>
</div></p></li>
</ul>
</div>
</section>
<section class="slide" id="ds310-datastax-enterprise-search-with-apache-solr">
<h2>DS310 DataStax Enterprise Search with Apache Solr</h2>
<div class="ulist">
<ul>
<li>Solr search queries</li>
<li>Inverted indexes</li>
<li>Document scoring</li>
<li>Term modifiers</li>
<li>Solr schema</li>
</ul>
</div>
</section>
<section class="slide" id="ds320-datastax-enterprise-analytics-with-apache-spark">
<h2>DS320 DataStax Enterprise Analytics with Apache Spark</h2>
<div class="ulist">
<ul>
<li>Explores using Scala on Spark to query data for analytical purposes</li>
<li><p>
Resilient Distributed Datasets (RDDs)<div class="ulist">
<ul>
<li>Aggregation</li>
<li>Grouping</li>
<li>Sorting</li>
</ul>
</div></p></li>
<li>Joins!</li>
<li>Data Shuffling</li>
<li>Streaming</li>
<li>Spark SQL</li>
</ul>
</div>
</section>
<div aria-role="navigation">
<a class="deck-prev-link" href="#" title="Previous">
<i class="icon-chevron-with-circle-left"></i>
</a>
<a class="deck-next-link" href="#" title="Next">
<i class="icon-chevron-with-circle-right"></i>
</a>
</div>
<form action="." class="goto-form" method="get">
<label for="goto-slide">Go to Slide:</label>
<input id="goto-slide" list="goto-datalist" name="slidenum" type="text" />
<datalist id="goto-data-list"></datalist>
<input type="submit" value="Go" />
</form>
</div>
<script src="deck.js/jquery.min.js"></script>
<script src="deck.js/d3.v2.js"></script>
<script src="deck.js/jquery-ui.min.js"></script>
<script src="deck.js/core/deck.core.js"></script>
<script src="deck.js/extensions/scale/deck.scale.js"></script>
<script src="deck.js/extensions/goto/deck.goto.js"></script>
<script src="deck.js/extensions/navigation/deck.navigation.js"></script>
<script src="deck.js/extensions/split/deck.split.js"></script>
<script src="deck.js/extensions/animation/deck.animation.js"></script>
<script src="deck.js/extensions/deck.js-notes/deck.notes.js"></script>
<script src="deck.js/extensions/goto/deck.goto.js"></script>
<script src="deck.js/extensions/clone/deck.clone.js"></script>
<script src="deck.js/extensions/svg/svg.min.js"></script>
<script src="js/course.js"></script>
<footer>
<div class="flex-element deck-course">
<p>&copy; 2016 DataStax. Use only with permission. &bull;
<span class="course-title">DS201: DataStax Enterprise Foundations of Apache Cassandra</span></p>
</div>
<div class="flex-element deck-brand">
<a href="http://academy.datastax.com" target="blank">DataStax Academy</a>
</div>
<div class="deck-progressbar">
<span></span>
</div>
</footer>
<script type="text/javascript">
  //<![CDATA[
    (function($, deck, undefined) {
      $.deck.defaults.keys['previous'] = [8, 33, 37, 39];
      $.deck.defaults.keys['next'] = [13, 32, 34, 39];
    
      $.extend(true, $[deck].defaults, {
          countNested: false
      });
    
      $.deck('.slide');
      $.deck('disableScale');
    })(jQuery, 'deck');
  //]]>
</script>
<script type="text/javascript">
  //<![CDATA[
    $(document).bind('deck.change', function(event, from, to) {
      var width = to / ($.deck('getSlides').length - 1) * 100;
      $('.deck-progressbar span').css('width', width + '%');
    });
  //]]>
</script>
</body>
</html>